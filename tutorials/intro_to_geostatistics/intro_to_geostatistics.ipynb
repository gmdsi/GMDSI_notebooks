{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemu\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import geostat_helpers as gh\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import normaltest\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geostatistics \n",
    "\n",
    "This notebook is a very high-level introduction to geostatisics. Some definitions from Geoff Bohling http://people.ku.edu/~gbohling/cpe940/Variograms.pdf\n",
    "\n",
    "> “_Geostatistics: study of phenomena that vary in space and/or time_”\n",
    "(Deutsch, 2002)\n",
    "\n",
    "> “_Geostatistics can be regarded as a collection of numerical techniques that deal with the characterization of spatial attributes, employing primarily random models in a manner similar to the way in which time series analysis characterizes temporal data._”\n",
    "(Olea, 1999)\n",
    "\n",
    "> “_Geostatistics offers a way of describing the spatial continuity of natural phenomena and provides adaptations of classical regression techniques to take advantage of this continuity._” \n",
    "(Isaaks and Srivastava, 1989)\n",
    "\n",
    "> Geostatistics deals with spatially _autocorrelated_ data.\n",
    "\n",
    "> \"_Autocorrelation: correlation between elements of a series and others from the same series separated from them by a given interval._\"\n",
    "(Oxford American Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Concepts\n",
    "\n",
    "1. Variogram modeling -- a way to characterize spatial correlation\n",
    "2. Kriging -- a best linear unbiased estimate (BLUE) for interpolation with minimum variance. There are several flavors - we will focus on Ordinary Kriging\n",
    "3. Stochastic Simulation -- http://petrowiki.org/Geostatistical_conditional_simulation\n",
    "4. Beyond this multi-Gaussian approach focused on the relationships among pairs of points, there is _multiple point geostatistics_ as well using training images and more complex shapes\n",
    "\n",
    "These concepts each build on each other. We will briefly touch on the first two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Field\n",
    "Let's cook up a quick random field and explore the spatial structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,Z,v,gs,sample_df = gh.data_cooker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Field\n",
    "Pretend (key word!) that this is a hydraulic conductivity field. What do you think? Any _autocorrelation_ here? \n",
    "Note how values spread _continuously_. Points which are close together have similar values. They are not _entirely_ random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to the Real-World\n",
    "\n",
    "In practice, we would typically only know the values at a few points (and probably not perfectly). (Think pumping tests or other point-sample site characterisation methods.) So how do we go from these \"few\" samples to a continuous parameter field?\n",
    "\n",
    ">note: the default number of samples we use here is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.field_scatterplot(sample_df.x,sample_df.y,sample_df.z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Assumptions:\n",
    "   1. The values are second order stationary (the mean and variance are relatively constant) \n",
    "   2. The values are multi-Gaussian (e.g. normally distributed)\n",
    "\n",
    "If we inspect our generated data, we see that it is normally distributed, so that's good. (_side note: of course it is, we generated it using geostaticsits..so we are cheating here..._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Z.ravel(), bins=50)\n",
    "x=np.linspace(70,130,100)\n",
    "plt.plot(x,sps.norm.pdf(x, np.mean(Z),np.std(Z))*len(Z.ravel()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_df.z, bins=50)\n",
    "x=np.linspace(70,130,100)\n",
    "plt.plot(x,sps.norm.pdf(x, np.mean(sample_df.z),np.std(sample_df.z))*len(sample_df.z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purity is commendable, but in practice we are going to violate some of these assumptions for sure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variograms\n",
    "At the heart of geostatistics is some kind of model expressing the variability of properties in a field. This is a \"variogram\" and we can explore it based on the following empirical formula:\n",
    "\n",
    " $$\\hat{\\gamma}\\left(h\\right)=\\frac{1}{2\\left(h\\right)}\\left(z\\left(x_1\\right)-z\\left(x_2\\right)\\right)^2$$\n",
    " \n",
    "where $x_1$ and $x_2$ are the locations of two $z$ data points separated by distance $h$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot these up we get something called a cloud plot showing $\\hat\\gamma$ for all pairs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty messy, so typically it is evaluated in bins, and usually only over half the total possible distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that this was assuming perfect observations. What if there was ~10% noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z_noisy,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geostatistics is making the assumption that you can model the variability of this field using a variogram. The variogram is closely related to covariance. We take advantage of a few assumptions to come up with a few functional forms that should characterize this behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variograms in `pyemu`\n",
    "`pyemu` supports three variogram models. (As do most of the utilities in the PEST-suite of software.)\n",
    "This follows the _GSLIB_ terminology:\n",
    " 1. *Spherical*  \n",
    " $\\gamma\\left(h\\right)=c\\times\\left[1.5\\frac{h}{a}-0.5\\frac{h}{a}^3\\right]$ if $h<a$\n",
    " $\\gamma\\left(h\\right)=c$ if $h \\ge a$  \n",
    "  \n",
    " 2. *Exponential*  \n",
    " $\\gamma\\left(h\\right)=c\\times\\left[1-\\exp\\left(-\\frac{h}{a}\\right)\\right]$  \n",
    "  \n",
    " 3. *Gaussian*  \n",
    " $\\gamma\\left(h\\right)=c\\times\\left[1-\\exp\\left(-\\frac{h^2}{a^2}\\right)\\right]$  \n",
    "  \n",
    " $h$ is the separation distance, and $a$ is the range. `contribution` is the variogram value at which the variogram levels off. Also called the `sill`, this value is the maximum variability between points.\n",
    " The sill is reached at about $a$ for the *Spherical* model, $2a$ for the *Gaussian*, and $3a$ for the *Exponential*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these look like?\n",
    "\n",
    "For a consistent set of parameters:\n",
    " > a=500, c=10\n",
    " \n",
    " We can use `pyemu` to setup a geostatistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=500\n",
    "c=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a variogram object and, from that, build a geostatistical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Spherical_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.SphVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Exponential_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)\n",
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.plot([3*v.a,3*v.a],[0,v.contribution],'r:')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Gaussian_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.GauVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)\n",
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.plot([7/4*v.a,7/4*v.a],[0,v.contribution],'r:')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating from Sparse Data\n",
    "So how do we go from a sample of measurments (i.e. our 50 points, sampled frmo the field at the start of the notebook) and generate a continuous filed? If we fit an appropriate model ($\\gamma$) to the empirical variogram ($\\hat\\gamma$), we can use that structure for interpolation from sparse data.\n",
    "\n",
    "Experiment below with changing the `new_a` and `new_c` variables and/or the variogram type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,50)\n",
    "new_c=10\n",
    "new_a=500.0\n",
    "\n",
    "v_fit = pyemu.geostats.ExpVario(contribution=new_c,a=new_a)\n",
    "gs_fit = pyemu.geostats.GeoStruct(variograms=v_fit)\n",
    "gs_fit.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = gs_fit.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform Kriging to interpolate using this variogram and our \"sample data\". First make an Ordinary Kriging object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pyemu.geostats.OrdinaryKrige(gs_fit,sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to calculate factors (we only do this once - takes a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactors = k.calc_factors(X.ravel(),Y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easiest to think of these factors as weights on surrounding point to calculate a weighted average of the surrounding values. The weight is a function of the distance - points father away have smaller weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now interpolate from our sampled points to a grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_interp = gh.geostat_interpolate(X,Y,k.interp_data, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,Z_interp, title='reconstruction', vlims=[72,92])\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z,title='truth', vlims=[72,92])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,kfactors.err_var.values.reshape(X.shape), title='Variance of Estimate')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,np.abs(Z-Z_interp), title='Actual Differences')\n",
    "ax.plot(sample_df.x,sample_df.y, 'yo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if our data were noisy?\n",
    "\n",
    "Try and get a good fit by adjusting the `new_c` and `new_a` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z_noisy,30)\n",
    "new_c=50.0\n",
    "new_a=350.0\n",
    "\n",
    "# select which kind of variogram here because in reality we don't know, right?\n",
    "v_fit = pyemu.geostats.ExpVario(contribution=new_c,a=new_a)\n",
    "gs_fit = pyemu.geostats.GeoStruct(variograms=v_fit, nugget=50)\n",
    "gs_fit.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = gs_fit.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again make the Kriging Object and the factors and interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pyemu.geostats.OrdinaryKrige(gs_fit,sample_df)\n",
    "kfactors = k.calc_factors(X.ravel(),Y.ravel())\n",
    "Z_interp = gh.geostat_interpolate(X,Y,k.interp_data, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,Z_interp, vlims=[72,92], title='reconstruction')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z, vlims=[72,92],title='truth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,kfactors.err_var.values.reshape(X.shape), title='Variance of Estimate')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,np.abs(Z-Z_interp), title='Actual Differences')\n",
    "ax.plot(sample_df.x,sample_df.y, 'yo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral simulation\n",
    "\n",
    "Because pyemu is pure python (and because the developers are lazy), it only implments spectral simulation for grid-scale field generation.  For regular grids without anisotropy and without conditioning data (\"known\" property values), it is identical to sequential gaussian simulation.\n",
    "\n",
    "Each of hte plots below illustrate the effect of different values of `a`. Experiment with changing `a`,  `contribution`, etc to get a feel for how they affect spatial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,1, )\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,5)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,500)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further resources and information\n",
    "1. These concepts are used for pilot point interpolation in PEST:\n",
    "    - In the GW utilities in PEST (http://www.pesthomepage.org/Groundwater_Utilities.php) \n",
    "    - The main tools are also available in `pyemu` -- we'll use that in the class\n",
    "2. The Stanford Geostatistical Modeling Software (SGeMS: http://sgems.sourceforge.net/) is a nice GUI for geostatistical modeling, but it's not being maintained anymore.\n",
    "3. Python libraries for geostistics:\n",
    "    - [`pysgems`](https://github.com/robinthibaut/pysgems) uses SGEMS within Python \n",
    "    - [`Scikit-GStat`](https://github.com/mmaelicke/scikit-gstat). A tutorial can be found [here](https://guillaumeattard.com/geostatistics-applied-to-hydrogeology-with-scikit-gstat/)\n",
    "4. `R` has a package: http://rgeostats.free.fr/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

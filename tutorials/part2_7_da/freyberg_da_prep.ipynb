{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for sequential data assimilation\n",
    "\n",
    "Sequential state-parameter estimation is a whole new beast for the PEST world.  Every other tool in PEST and PEST++ operate on the concept of \"batch\" estimation, where the model is run forward for the full simulation period and PEST(++) simply calls the model and reads the results.  In sequential estimation, PESTPP-DA takes control of the advancing of simulation time.  This opens up some powerful new analyses but requires us to heavily modify the PEST interface and model itself.  This horrible notebook does that...\n",
    "\n",
    "### The modified Freyberg PEST dataset\n",
    "\n",
    "The modified Freyberg model is introduced in another tutorial notebook (see \"freyberg intro to model\"). The current notebook picks up following the \"freyberg psfrom pest setup\" notebook, in which a high-dimensional PEST dataset was constructed using `pyemu.PstFrom`. You may also wish to go through the \"intro to pyemu\" notebook beforehand.\n",
    "\n",
    "The next couple of cells load necessary dependencies and call a convenience function to prepare the PEST dataset folder for you. This is the same dataset that was constructed during the \"freyberg pstfrom pest setup\" tutorial. Simply press `shift+enter` to run the cells.\n",
    "\n",
    "### Admin\n",
    "\n",
    "The next couple of cells load necessary dependencies and call a convenience function to prepare the PEST dataset folder for you. Simply press `shift+enter` to run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_da_template')\n",
    "\n",
    "org_t_d = os.path.join(\"..\",\"part2_2_obs_and_weights\",\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_2_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")\n",
    "\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "shutil.copytree(org_t_d,t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the model itself\n",
    "\n",
    "There are several modifications we need to make to both the model and pest interface in order to go from batch estimation to sequential estimation.  First, we need to make the model a single stress period model - PESTPP-DA will take control of the advancement of simulation time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(t_d,\"freyberg6.tdis\"),'w') as f:\n",
    "    f.write(\"# new tdis written hastily at {0}\\n]\\n\".format(datetime.now()))\n",
    "    f.write(\"BEGIN options\\n  TIME_UNITS days\\nEND options\\n\\n\")\n",
    "    f.write(\"BEGIN dimensions\\n  NPER 1\\nEND dimensions\\n\\n\")\n",
    "    f.write(\"BEGIN perioddata\\n  1.0  1 1.0\\nEND perioddata\\n\\n\")\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just make sure we havent done something dumb (er than usual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"mf6\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the hard part: modifying the interface from batch to sequential\n",
    "\n",
    "## This is going to be rough...\n",
    "\n",
    "First, let's assign cycle numbers to the time-varying parameters and their template files.  The \"cycle\" concept is core to squential estimation with PESTPP-DA.  A cycle can be thought of as a unit of simulation time that we are interested in. In the PEST interface, a cycle defines a set of parameters and observations, so you can think of a cycle as a \"sub-problem\" in the PEST since - PESTPP-DA creates this subproblem under the hood for us. For a given cycle, we will \"assimilate\" all non-zero weighted obsevations in that cycle using the adjustable parameters and states in that cycle.  If a parameter/observation (and associated input/outputs files) are assigned a cycle value of -1, that means it applies to all cycles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_path = os.path.join(t_d, 'freyberg_mf6.pst')\n",
    "pst = pyemu.Pst(pst_path)\n",
    "if \"observed\" not in pst.observation_data.columns:\n",
    "    raise Exception(\"you need to run the '/part2_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pst.model_input_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"cycle\"] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to assign the template file info associated with time-varying SFR parameters to the appropriate cycle - this includes resetting the actual model-input filename since we only have only stress period in the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = df.loc[df.pest_file.apply(lambda x: \"sfr\" in x and \"cond\" not in x),:]\n",
    "sfrdf.loc[:,\"inst\"] = sfrdf.pest_file.apply(lambda x: int(x.split(\"inst\")[1].split(\"_\")[0]))\n",
    "sfrdf.loc[:,\"model_file\"] = sfrdf.model_file.iloc[0]\n",
    "sfrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[sfrdf.index,\"cycle\"] = sfrdf.inst.values\n",
    "df.loc[sfrdf.index,\"model_file\"] = sfrdf.model_file.values\n",
    "\n",
    "df.loc[sfrdf.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for the template files associated with the WEL package time-varying parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weldf = df.loc[df.pest_file.str.contains('wel'),:]\n",
    "df.loc[weldf.index,\"cycle\"] = weldf.pest_file.apply(lambda x: int(x.split(\"inst\")[1].split(\"_\")[0]))\n",
    "grdf = weldf.loc[weldf.pest_file.str.contains(\"welgrd\"),:]\n",
    "df.loc[grdf.index,\"model_file\"] = grdf.model_file.iloc[0]\n",
    "cndf = weldf.loc[weldf.pest_file.str.contains(\"welcst\"),:]\n",
    "df.loc[cndf.index,\"model_file\"] = cndf.model_file.iloc[0]\n",
    "\n",
    "df.loc[weldf.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for the template files associated with the RCH package time-varying parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rchdf = df.loc[df.pest_file.apply(lambda x: \"rch\" in x and \"tcn\" in x),:]\n",
    "df.loc[rchdf.index,\"cycle\"] = rchdf.pest_file.apply(lambda x: int(x.split(\"tcn\")[0].split(\"_\")[-1])-1)\n",
    "df.loc[rchdf.index,\"model_file\"] = rchdf.model_file.iloc[0]\n",
    "df.loc[rchdf.index,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for rch pp and grd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.pest_file.apply(lambda x: \"rch\" in x ),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rchgrdf = df.loc[df.pest_file.apply(lambda x: \"rch\" in x and \"gr\" in x),:]\n",
    "df.loc[rchgrdf.index,\"cycle\"] = rchgrdf.pest_file.apply(lambda x: int(x.split(\"gr\")[0].split(\"rchrecharge\")[-1])-1)\n",
    "df.loc[rchgrdf.index,\"model_file\"] = rchgrdf.model_file.iloc[0]\n",
    "df.loc[rchgrdf.index,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rchppdf = df.loc[df.pest_file.apply(lambda x: \"rch\" in x and \"pp\" in x),:]\n",
    "df.loc[rchppdf.index,\"cycle\"] = rchppdf.pest_file.apply(lambda x: int(x.split(\"pp\")[0].split(\"rchrecharge\")[-1])-1)\n",
    "df.loc[rchppdf.index,\"model_file\"] = rchppdf.model_file.iloc[0]\n",
    "df.loc[rchppdf.index,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to set the cycle numbers for the parmaeters themselves - good luck doing this with recarrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.loc[:,\"cycle\"] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time-varying well parameters - the parmaeter instance (\"inst\") value assigned by `PstFrom` correspond to the zero-based stress period number, so we can just use that as the cycle value - nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = par.loc[par.parnme.str.contains(\"wel\"),:]\n",
    "par.loc[wpar.index,\"cycle\"] = wpar.inst.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for sfr time-varying parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spar = par.loc[par.parnme.apply(lambda x: \"sfr\" in x and \"cond\" not in x),:]\n",
    "par.loc[spar.index,\"cycle\"] = spar.inst.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for time-varying recharge parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpar = par.loc[par.parnme.apply(lambda x: \"rch\" in x and \"tcn\" in x),:]\n",
    "par.loc[rpar.index,\"cycle\"] = rpar.parnme.apply(lambda x: int(x.split(\"tcn\")[0].split(\"_\")[-1])-1)\n",
    "\n",
    "\n",
    "rgrpar = par.loc[par.parnme.apply(lambda x: \"rch\" in x and \"gr\" in x),:]\n",
    "par.loc[rgrpar.index,\"cycle\"] = rgrpar.parnme.apply(lambda x: int(x.split(\"gr\")[0].split(\"rchrecharge\")[-1])-1)\n",
    "\n",
    "\n",
    "rpppar = par.loc[par.parnme.apply(lambda x: \"rch\" in x and \"pp\" in x),:]\n",
    "par.loc[rpppar.index,\"cycle\"] = rpppar.parnme.apply(lambda x: int(x.split(\"pp\")[0].split(\"rchrecharge\")[-1])-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add a special parameter that will be used to control the length of the stress period that the single-stress-period model will simulate.  As usual, we do this with a template file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(t_d,\"freyberg6.tdis.tpl\"),'w') as f:\n",
    "    f.write(\"ptf ~\\n\")\n",
    "    f.write(\"# new tdis written hastily at {0}\\n]\\n\".format(datetime.now()))\n",
    "    f.write(\"BEGIN options\\n  TIME_UNITS days\\nEND options\\n\\n\")\n",
    "    f.write(\"BEGIN dimensions\\n  NPER 1\\nEND dimensions\\n\\n\")\n",
    "    f.write(\"BEGIN perioddata\\n  ~  perlen  ~  1 1.0\\nEND perioddata\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_parameters(os.path.join(t_d,\"freyberg6.tdis.tpl\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a dummy parameter that is the cycle number - this will be written into the working dir at runtime and can help us get our pre and post processors going for sequential estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpl_file = os.path.join(t_d,\"cycle.dat.tpl\")\n",
    "with open(tpl_file,'w') as f:\n",
    "    f.write(\"ptf ~\\n\")\n",
    "    f.write(\"cycle_num ~  cycle_num   ~\\n\")\n",
    "pst.add_parameters(tpl_file,pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[\"perlen\",\"partrans\"] = \"fixed\"\n",
    "pst.parameter_data.loc[\"perlen\",\"cycle\"] = -1\n",
    "pst.parameter_data.loc[\"cycle_num\",\"partrans\"] = \"fixed\"\n",
    "pst.parameter_data.loc[\"cycle_num\",\"cycle\"] = -1\n",
    "pst.model_input_data.loc[pst.model_input_data.index[-2],\"cycle\"] = -1\n",
    "pst.model_input_data.loc[pst.model_input_data.index[-1],\"cycle\"] = -1\n",
    "pst.model_input_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `perlen` needs to change over cycles (month to month), we a way to tell PESTPP-DA to change it.  We could setup separate parameters and template for each cycle (e.g. `perlen_0`,`perlen_1`,`perlen_2`, etc, for cycle 0,1,2, etc), but this is cumbersome.  Instead, we can use a parameter cycle table to specific the value of the `perlen` parameter for each cycle (only fixed parameters can be treated this way...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=org_t_d,load_only=[\"dis\"])\n",
    "org_perlen = sim.tdis.perioddata.array[\"perlen\"]\n",
    "org_perlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"perlen\":org_perlen},index=np.arange(org_perlen.shape[0]))\n",
    "df.loc[:,\"cycle_num\"] = df.index.values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_csv(os.path.join(t_d,\"par_cycle_table.csv\"))\n",
    "pst.pestpp_options[\"da_parameter_cycle_table\"] = \"par_cycle_table.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation data\n",
    "\n",
    "Now for the observation data - yuck!  In the existing PEST interface, we include simulated GW level values in all active cells as observations, but then we also used the MF6 head obs process to make it easier for us to get the obs v sim process setup.  Here, we will ditch the MF6 head obs process and just rely on the arrays of simulated GW levels - these will be included in every cycle.  The arrays of simulated groundwater level in every active model cell will serve two roles: outputs to compare with data for assimilation (at specific locations in space and time) and also as dynamic states that will be linked to the initial head parameters - this is where things will get really exciting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there is not an easy way to carry the particle-based forecasts, so let's drop those..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"freyberg_mp.mpend.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for temporal-based difference observations...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"sfr.tdiff.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"heads.tdiff.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we will drop the MF6 head obs type observations - remember, we will instead rely on the arrays of simulated GW levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pst.drop_observations(os.path.join(t_d,\"heads.csv.ins\"),pst_path=\".\")\n",
    "\n",
    "#sdf = pst.drop_observations(os.path.join(t_d,\"sfr.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for i in pst.model_output_data.model_file if i.startswith('hdslay')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some really nasty hackery:  we are going to modify the remaining stress-period-based instruction files to only include one row of instructions (since we only have one stress period now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = None\n",
    "for ins_file in pst.model_output_data.pest_file:\n",
    "    if ins_file.startswith(\"hdslay\") and ins_file.endswith(\"_t1.txt.ins\"):\n",
    "        print('not dropping:', ins_file)\n",
    "        continue\n",
    "    elif ins_file.startswith(\"hdslay\"):\n",
    "        df = pst.drop_observations(os.path.join(t_d,ins_file),pst_path=\".\")\n",
    "        print('dropping:',ins_file)\n",
    "    else:\n",
    "        lines = open(os.path.join(t_d,ins_file),'r').readlines()\n",
    "        df = pst.drop_observations(os.path.join(t_d,ins_file),pst_path=\".\")\n",
    "        if ins_file == \"sfr.csv.ins\":\n",
    "            sfrdf = df\n",
    "        with open(os.path.join(t_d,ins_file),'w') as f:\n",
    "            for line in lines[:3]:\n",
    "                f.write(line.replace(\"_totim:3652.5\",\"\").replace(\"_time:3652.5\",\"\"))\n",
    "        pst.add_observations(os.path.join(t_d,ins_file),pst_path=\".\")\n",
    "assert sfrdf is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in pst.model_output_data.model_file if i.startswith('hdslay')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning observation values and weights\n",
    "\n",
    "Time to work out a mapping from the MF6 head obs data (that have the actual head observations and weight we want) to the array based GW level observations.  We will again use a special set of PESTPP-DA specific options to help us here.  Since the observed value of GW level and the weights change through time (e.g. across cycles) but we are recording the array-based GW level observations every cycle, we need a way to tell PESTPP-DA to use specific `obsval`s and `weight`s for a given cycle.  `da_observation_cycle_table` and `da_weight_cycle_table` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.loc[:,\"k\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[1]))\n",
    "hdf.loc[:,\"i\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[2]))\n",
    "hdf.loc[:,\"j\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[3]))\n",
    "hdf.loc[:,\"time\"] = hdf.time.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = hdf.usecol.unique()\n",
    "sites.sort()\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code bit, we will process each MF6 head obs record (which includes `obsval` and `weight` for each stress period at each L-R-C location) and align that with corresponding (L-R-C) array-based GW level observation.  Then just collate those records into obs and weight cycle table. Note: we only want to include sites that have at least one non-zero weighted observation.  easy as!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.try_parse_name_metadata()\n",
    "obs = pst.observation_data\n",
    "hdsobs = obs.loc[obs.obsnme.str.contains(\"hdslay\"),:].copy()\n",
    "hdsobs.loc[:,\"i\"] = hdsobs.i.astype(int)\n",
    "hdsobs.loc[:,\"j\"] = hdsobs.j.astype(int)\n",
    "hdsobs.loc[:,\"k\"] = hdsobs.oname.apply(lambda x: int(x[-1])-1)\n",
    "odata = {}\n",
    "wdata = {}\n",
    "alldata = {}\n",
    "for site in sites:\n",
    "    sdf = hdf.loc[hdf.usecol==site,:].copy()\n",
    "    #print(sdf.weight)\n",
    "    \n",
    "    sdf.sort_values(by=\"time\",inplace=True)\n",
    "    k,i,j = sdf.k.iloc[0],sdf.i.iloc[0],sdf.j.iloc[0]\n",
    "    hds = hdsobs.loc[hdsobs.apply(lambda x: x.i==i and x.j==j and x.k==k,axis=1),:].copy()\n",
    "    #assert hds.shape[0] == 1,site\n",
    "    obname = hds.obsnme.iloc[0]\n",
    "    print(obname)\n",
    "    alldata[obname] = sdf.obsval.values\n",
    "    if sdf.weight.sum() == 0:\n",
    "        continue\n",
    "    odata[obname] = sdf.obsval.values\n",
    "    wdata[obname] = sdf.weight.values\n",
    "    #print(site)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the SFR \"gage-1\" observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrobs = obs.loc[obs.obsnme.str.contains(\"oname:sfr\"),:].copy()\n",
    "sites = sfrdf.usecol.unique()\n",
    "sites.sort()\n",
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites:\n",
    "    sdf = sfrdf.loc[sfrdf.usecol==site,:].copy()\n",
    "    sdf.loc[:,\"time\"] = sdf.time.astype(float)\n",
    "    \n",
    "    sdf.sort_values(by=\"time\",inplace=True)\n",
    "    sfr = sfrobs.loc[sfrobs.usecol==site,:].copy()\n",
    "    assert sfr.shape[0] == 1,sfr\n",
    "    alldata[sfr.obsnme.iloc[0]] = sdf.obsval.values\n",
    "    if sdf.weight.sum() == 0:\n",
    "        continue\n",
    "    odata[sfr.obsnme.iloc[0]] = sdf.obsval.values\n",
    "    wdata[sfr.obsnme.iloc[0]] = sdf.weight.values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buidling the observation and weight cycle tables\n",
    "\n",
    "Since we have observations at the same spatial locations across cycles, but we have only one \"observation\" (and there for `obsval` and `weight`) for that location in the control file.  So we can use the pestpp-da specific options: the observation and weight cycle table.\n",
    "\n",
    "Form the obs cycle table as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(odata)\n",
    "df.index.name = \"cycle\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_csv(os.path.join(t_d,\"obs_cycle_table.csv\"))\n",
    "pst.pestpp_options[\"da_observation_cycle_table\"] = \"obs_cycle_table.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep for the weight cycle table also.  As a safety check, PESTPP-DA requires any observation quantity that ever has a non-zero weight for any cycle to have a non-zero weight in `* observation data` (this weight value is not used, its more of just a flag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[:,\"weight\"] = 0\n",
    "obs.loc[:,\"cycle\"] = -1\n",
    "df = pd.DataFrame(wdata)\n",
    "df.index.name = \"cycle\"\n",
    "wsum = df.sum()\n",
    "wsum = wsum.loc[wsum>0]\n",
    "print(wsum)\n",
    "obs.loc[wsum.index,\"weight\"] = 1.0\n",
    "\n",
    "df.T.to_csv(os.path.join(t_d,\"weight_cycle_table.csv\"))\n",
    "pst.pestpp_options[\"da_weight_cycle_table\"] = \"weight_cycle_table.csv\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to see here...let's save `alldata` to help us plot the results of PESTPP-DA later WRT forecasts and un-assimilated observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(alldata)\n",
    "df.index.name = \"cycle\"\n",
    "df.to_csv(os.path.join(t_d,\"alldata.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The state mapping between pars and obs\n",
    "\n",
    "Ok, now for our next trick...\n",
    "\n",
    "We need to tell PESTPP-DA that we want to use dynamic states.  This is tricky concept for us \"batch\" people, but conceptually, these states allow PESTPP-DA to coherently advance the model in time.  Just like MF6 would take the final simulated GW levels at the end of stress period and set them as the starting heads for the next stress, so too must PESTPP-DA. Otherwise, there would be no temporal coherence in the simulated results.  What is exciting about this is that PESTPP-DA also has the opportunity to \"estimate\" the start heads for each cycle, along with the other parameters.  Algorithmically, PESTPP-DA sees these \"states\" just as any other parameter to estimate for a given cycle.  Conceptually, treating the initial states for each cycle as uncertain and therefore adjustable, is one way to explicitly acknowledge that the model is \"imperfect\" and therefore the initial conditions for each cycle are \"imperfect\" e.g. uncertain!  How cool!\n",
    "\n",
    "The way we tell PESTPP-DA about the dynamic state linkage between observations and parameters is by either giving the parameters and observations identical names, or by adding a column to the `* observation data` dataframe that names the parameter that the observation links to.  We will do the latter here - this column must be named \"state_par_link\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[:,\"state_par_link\"] = \"\"\n",
    "hdsobs = obs.loc[obs.obsnme.str.contains(\"hdslay\"),:].copy()\n",
    "hdsobs.loc[:,\"i\"] = hdsobs.i.astype(int)\n",
    "hdsobs.loc[:,\"j\"] = hdsobs.j.astype(int)\n",
    "hdsobs.loc[:,\"k\"] = hdsobs.oname.apply(lambda x: int(x[-1])-1)\n",
    "hdsobs.loc[:,\"kij\"] = hdsobs.apply(lambda x: (x.k,x.i,x.j),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "strtpar = par.loc[par.parnme.str.contains(\"strt\"),:].copy()\n",
    "strtpar.loc[:,\"i\"] = strtpar.i.astype(int)\n",
    "strtpar.loc[:,\"j\"] = strtpar.j.astype(int)\n",
    "strtpar.loc[:,\"k\"] = strtpar.pname.apply(lambda x: int(x[-1])-1)\n",
    "strtpar.loc[:,\"kij\"] = strtpar.apply(lambda x: (x.k,x.i,x.j),axis=1)\n",
    "spl = {kij:name for kij,name in zip(strtpar.kij,strtpar.parnme)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[hdsobs.obsnme,\"state_par_link\"] = hdsobs.kij.apply(lambda x: spl.get(x,\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[hdsobs.obsnme,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: we need to modify the multiplier-parameter process since we now have a single-stress-period model.  This is required if you are using `PstFrom`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(t_d,\"mult2model_info.csv\"),index_col=0)\n",
    "ifiles = set(pst.model_input_data.model_file.tolist())\n",
    "#print(df.mlt_file.unique())\n",
    "new_df = df.loc[df.mlt_file.apply(lambda x: pd.isna(x) or x in ifiles),:]\n",
    "#new_df.shape,df.shape\n",
    "#new_df.to_csv(os.path.join(t_d,\"mult2model_info.csv\"))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"cycle\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr = df.loc[df.model_file.str.contains(\"sfr_perioddata\"),:].copy()\n",
    "df.loc[sfr.index,\"cycle\"] = sfr.model_file.apply(lambda x: int(x.split(\"_\")[-1].split(\".\")[0])-1)\n",
    "df.loc[sfr.index.values[1:],\"model_file\"] = sfr.model_file.iloc[0]\n",
    "df.loc[sfr.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rch = df.loc[df.model_file.str.contains(\"rch\"),:]\n",
    "df.loc[rch.index,\"cycle\"] = rch.model_file.apply(lambda x: int(x.split('_')[-1].split(\".\")[0])-1)\n",
    "df.loc[rch.index.values[1:],\"model_file\"] = rch.model_file.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel = df.loc[df.model_file.str.contains(\"wel\"),:].copy()\n",
    "df.loc[wel.index,\"cycle\"] = wel.model_file.apply(lambda x: int(x.split('_')[-1].split(\".\")[0])-1)\n",
    "df.loc[wel.index.values[1:],\"model_file\"] = wel.model_file.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[wel.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.cycle!=-1,[\"org_file\",\"model_file\",\"cycle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(t_d,\"mult2model_info.global.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(\"prep_mult.py\",os.path.join(t_d,\"prep_mult.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(os.path.join(t_d,\"forward_run.py\"),'r').readlines()\n",
    "with open(os.path.join(t_d,\"forward_run.py\"),'w') as f:\n",
    "    for line in lines:\n",
    "        if \"apply_list_and_array_pars\" in line:\n",
    "            f.write(\"    pyemu.os_utils.run('python prep_mult.py')\\n\")\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMG that was brutal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options.pop(\"forecasts\",None)\n",
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(t_d,\"freyberg_mf6.pst\"),version=2)\n",
    "pyemu.os_utils.run(\"pestpp-da freyberg_mf6.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that takes a lot longer...this is the price of sequential estimation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(t_d) if \".base.obs.csv\" in f]\n",
    "files.sort()\n",
    "print(files)\n",
    "pr_oes = {int(f.split(\".\")[1]):pd.read_csv(os.path.join(t_d,f),index_col=0) for f in files[:-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otab = pd.read_csv(os.path.join(t_d,\"obs_cycle_table.csv\"),index_col=0)\n",
    "wtab = pd.read_csv(os.path.join(t_d,\"weight_cycle_table.csv\"),index_col=0)\n",
    "ad_df = pd.read_csv(os.path.join(t_d,\"alldata.csv\"),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "nzobs = obs.loc[pst.nnz_obs_names,:]\n",
    "nzobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in pst.nnz_obs_names:\n",
    "    fig,axes = plt.subplots(1,1,figsize=(10,3))\n",
    "    axes=[axes]\n",
    "    for kper,oe in pr_oes.items():\n",
    "        axes[0].scatter([kper]*oe.shape[0],oe.loc[:,o].values,marker=\".\",c=\"0.5\",alpha=0.5)\n",
    "\n",
    "    ovals = otab.loc[o,:].values\n",
    "    wvals = wtab.loc[o,:].values\n",
    "    ylim = axes[0].get_ylim()\n",
    "\n",
    " \n",
    "    xlim = axes[0].get_xlim()\n",
    "\n",
    "    ovals[wvals==0] = np.nan\n",
    "    axes[0].scatter(otab.columns.values,ovals,marker='^',c='r')\n",
    "    oval_lim = (np.nanmin(ovals),np.nanmax(ovals))\n",
    "    d = [ylim, (np.nanmin(ovals),np.nanmax(ovals))]\n",
    "    ylim =  min(d, key = lambda t: t[1])[0], max(d, key = lambda t: t[1])[-1]\n",
    "    axes[0].set_ylim(ylim)\n",
    "    axes[0].set_xlim(xlim)\n",
    "    axes[0].set_title(\"A) prior only: \"+o,loc=\"left\")\n",
    "    axes[0].set_xlabel(\"kper\")\n",
    "\n",
    "    \n",
    "    avals = ad_df.loc[:,o]\n",
    "    axes[0].scatter(ad_df.index.values,avals,marker='.',c='r')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

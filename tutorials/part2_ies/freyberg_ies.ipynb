{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Monte Carlo\n",
    "\n",
    "Prior-based (or \"unconstrained\") Monte Carlo is a usefull, but quite often underused, analysis. It is conceptually simple, does not require much in terms of algorithmic controls and forces the modeller to think about the prior parameter probability distribution - both the mean vector (i.e. the initial parameter values) and the prior parameter covariance matrix. \n",
    "\n",
    "The idea is simple: sample many sets of parameters (i.e. an ensemble) from a prior probability distribution and run the model forward for each realization in this ensemble and collate the results. Do not try and fit historical data (yet!). Do not throw any of the simulations out because they \"do not represent historical data well\". This allows us to explore the entire range of model outcomes across the (prior) range of parameter vaues. It let's us investigate model stability (e.g. can the model setup handle the parameters we are throwing at it?). It also let's us start to think critically about what observations the model will be able to match.\n",
    "\n",
    "Sometimes, it shows us that history matching is not required - saving us a whole lot of time and effort!\n",
    "\n",
    "In this notebook we will demonstrate:\n",
    " - how to use `pyemu` to run `pestpp` in parallel locally (that is on your machine only)\n",
    " - using `pestpp-swp` to do prior monte carlo with an existing geostatistically correlated prior parameter ensemble\n",
    " - using `pestpp-ies` to do prior monte carlo with an uncorrelated prior parameter ensemble \n",
    " - post-processing stochastic model outputs\n",
    "\n",
    "### 1. The modified Freyberg PEST dataset\n",
    "\n",
    "The modified Freyberg model is introduced in another tutorial notebook (see \"freyberg intro to model\"). The current notebook picks up following the \"freyberg psfrom pest setup\" notebook, in which a high-dimensional PEST dataset was constructed using `pyemu.PstFrom`. You may also wish to go through the \"intro to pyemu\" notebook beforehand.\n",
    "\n",
    "The next couple of cells load necessary dependencies and call a convenience function to prepare the PEST dataset folder for you. This is the same dataset that was constructed during the \"freyberg pstfrom pest setup\" tutorial. Simply press `shift+enter` to run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pyemu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# import pre-prepared convenience functions\n",
    "import herebedragons as hbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: if we move the obsvals and weights process to a sep notebook, \n",
    "# we need to also check that it has been executed. We could set an \n",
    "# \"observed\" column in the obs data to indicate that we have set obs vals and weights?\n",
    "\n",
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template')\n",
    "\n",
    "org_t_d = os.path.join(\"..\",\"part2_pstfrom_pest_setup\",\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_pstfrom_pest_setup/freyberg_pstfrom_pest_setup.ipynb' notebook\")\n",
    "\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "shutil.copytree(org_t_d,t_d)\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the convenience function to get the pre-preprepared PEST dataset;\n",
    "# this is the same dataset consutructed in the \"obs and weights\" tutorial\n",
    "#hbd.dir_cleancopy(org_d=os.path.join('..','..', 'models','freyberg_obs_and_weights'), \n",
    "#                new_d=t_d)\n",
    "# get and unzip the prior covariance JCB file\n",
    "#hbd.unzip(os.path.join('..','..','models','prior_cov.zip'), os.path.join(t_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the PEST control file as a `Pst` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d, 'freyberg_mf6.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the prior parameter ensemble we generated previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(t_d) if f.endswith(\".jcb\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pyemu.ParameterEnsemble.from_binary(pst=pst,filename=os.path.join(t_d,\"prior_pe.jcb\"))\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Ensemble in Parallel\n",
    "\n",
    "Here we are going to make use of the `pestpp-swp` to execute the prior monte carlo in parallel. `pestpp-swp` is a simple parametric sweep utility to run a collection of parameter sets in parallel and collate the results.\n",
    "\n",
    "So let's start by specifying the name of the prior parameter ensemble file that we generated previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options['ies_parameter_ensemble'] = 'prior_pe.jcb'\n",
    "pst.pestpp_options[\"ies_num_reals\"] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, re-write the PEST control file. If you open `freyberg_mf6.pst` in a text editor, you'll see a new PEST++ control variable has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0 # this is ignored by pestpp-swp, but we can use it to do a test run below\n",
    "pst.write(os.path.join(t_d, 'freyberg_mf6.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always good to do the 'ole `noptmax=0` test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies freyberg_mf6.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to run `pestpp-swp` in parallel. \n",
    "\n",
    "To speed up the process, you will want to distribute the workload across as many parallel agents as possible. Normally, you will want to use the same number of agents (or less) as you have available CPU cores. Most personal computers (i.e. desktops or laptops) these days have between 4 and 10 cores. Servers or HPCs may have many more cores than this. Another limitation to keep in mind is the read/write speed of your machines disk (e.g. your hard drive). PEST and the model software are going to be reading and writting lots of files. This often slows things down if agents are competing for the same resources to read/write to disk.\n",
    "\n",
    "The first thing we will do is specify the number of agents we are going to use.\n",
    "\n",
    "# Attention!\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we shall specify the PEST run-manager/master directory folder as `m_d`. This is where outcomes of the PEST run will be recorded. It should be different from the `t_d` folder, which contains the \"template\" of the PEST dataset. This keeps everything separate and avoids silly mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 3 # this is ignored by pestpp-swp, but we can use it to do a test run below\n",
    "pst.write(os.path.join(t_d, 'freyberg_mf6.pst'))\n",
    "m_d = os.path.join('master_ies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using `pestpp-swp`. Run it by pressing `shift+enter`.\n",
    "\n",
    "If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see `pestpp-swp`'s progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. The `master_priormc` folder is where the manager is running. \n",
    "\n",
    "This run should take several minutes to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking `pestpp-swp` from communicating with the agents (this is a common problem!).\n",
    "\n",
    "> **Pro Tip**: Running PEST from within a `jupyter notebook` has a tendency to slow things down and hog alot of RAM (at least if you are using Visual Studio Code, as I am). When modelling in the \"real world\" it is more efficient to implement workflows in scripts which you can call from the command line. For example, for this case it took me 20min when running `pestpp-swp` from the `jupyter notebook`, but only 5min when running form the comand line. If you inspect the tutorial folder, you will find a file named `run_swp.py` that accomplishes this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d, # the folder which contains the \"template\" PEST dataset\n",
    "                            'pestpp-ies', #the PEST software version we want to run\n",
    "                            'freyberg_mf6.pst', # the control file to use with PEST\n",
    "                            num_workers=num_workers, #how many agents to deploy\n",
    "                            worker_root='.', #where to deploy the agent directories; relative to where python is running\n",
    "                            master_dir=m_d, #the manager directory\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore the Outcomes\n",
    "\n",
    "By default, `pestpp-swp` writes the results of the parametric sweep to a csv file called `sweep_out.csv`.  This file has columns for each observation listed in the control file, plus columns for total phi and phi for each observation group (calculated using the weights in the control file).  It also has columns for the `input_run_id` and `failed_flag` to help you align these outputs with the inputs and also track any failed runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's check if any runs failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_oe = pyemu.ObservationEnsemble.from_csv(pst=pst,filename=os.path.join(m_d,\"freyberg_mf6.0.obs.csv\"))\n",
    "pt_oe = pyemu.ObservationEnsemble.from_csv(pst=pst,filename=os.path.join(m_d,\"freyberg_mf6.{0}.obs.csv\".format(pst.control_data.noptmax)))\n",
    "noise = pyemu.ObservationEnsemble.from_csv(pst=pst,filename=os.path.join(m_d,\"freyberg_mf6.obs+noise.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the distribution of Phi obtained for the ensemble. Some pretty high values there. But that's fine. We are not concerned with getting a \"good fit\" in prior MC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "pr_oe.phi_vector.apply(np.log10).hist(ax=ax,fc=\"0.5\",ec=\"none\",alpha=0.5,density=False)\n",
    "pt_oe.phi_vector.apply(np.log10).hist(ax=ax,fc=\"b\",ec=\"none\",alpha=0.5,density=False)\n",
    "_ = ax.set_xlabel(\"$log_{10}\\phi$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, perhaps coarser, method to quickly explore outcomes is to look at histograms of observations. \n",
    "\n",
    "The following figure groups obsevrations according to type (just to lump them together and make a smaller plot) and then plots histograms of observation values. Grey shaded columns represent simulated values from the prior. Red shaded columns represent the ensemble of measured values + noise. The grey columns should ideally be spread wider than the red columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the obs vs sim timeseries - everyone's fav!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.try_parse_name_metadata()\n",
    "obs = pst.observation_data.copy()\n",
    "obs = obs.loc[obs.oname.apply(lambda x: x in [\"hds\",\"sfr\"])]\n",
    "obs = obs.loc[obs.obgnme.apply(lambda x: x in pst.nnz_obs_groups),:]\n",
    "obs.obgnme.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogs = obs.obgnme.unique()\n",
    "fig,axes = plt.subplots(len(ogs),1,figsize=(10,5*len(ogs)))\n",
    "ogs.sort()\n",
    "for ax,og in zip(axes,ogs):\n",
    "    oobs = obs.loc[obs.obgnme==og,:].copy()\n",
    "    oobs.loc[:,\"time\"] = oobs.time.astype(float)\n",
    "    oobs.sort_values(by=\"time\",inplace=True)\n",
    "    tvals = oobs.time.values\n",
    "    onames = oobs.obsnme.values\n",
    "    [ax.plot(tvals,pr_oe.loc[i,onames].values,\"0.5\",lw=0.1,alpha=0.5) for i in pr_oe.index]\n",
    "    [ax.plot(tvals,pt_oe.loc[i,onames].values,\"b\",lw=0.1,alpha=0.5) for i in pt_oe.index]\n",
    "       \n",
    "    oobs = oobs.loc[oobs.weight>0,:]\n",
    "    tvals = oobs.time.values\n",
    "    onames = oobs.obsnme.values\n",
    "    [ax.plot(tvals,noise.loc[i,onames].values,\"r\",lw=0.1,alpha=0.5) for i in noise.index]\n",
    "    ax.plot(oobs.time,oobs.obsval,\"r-\",lw=2)\n",
    "    ax.set_title(og,loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we feel about these plots?  In general, its a really (really!) good fit...is that ok?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Forecasts\n",
    "\n",
    "As usual, we bring this story back to the forecasts - after all they are why we are modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.forecast_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in pst.forecast_names:\n",
    "    plt.figure()\n",
    "    ax = pr_oe.loc[:,forecast].hist(facecolor=\"0.5\",alpha=0.5)\n",
    "    ax = pt_oe.loc[:,forecast].hist(facecolor=\"b\",alpha=0.5)\n",
    "    \n",
    "    ax.set_title(forecast)\n",
    "    fval = pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([fval,fval],ax.get_ylim(),\"r-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruh roh!  The posterior isnt covering the correct values for several forecasts. But the prior does, so that implies there is somewhere between the prior and posterior we have now that is optimal with respect to the forecasts.  Luckily, we can just load up a previous iteration of ies results and use those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_to_use_as_posterior = 1\n",
    "pt_oe = pyemu.ObservationEnsemble.from_csv(pst=pst,filename=os.path.join(m_d,\"freyberg_mf6.{0}.obs.csv\".\\\n",
    "                                                                         format(iter_to_use_as_posterior)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "pr_oe.phi_vector.apply(np.log10).hist(ax=ax,fc=\"0.5\",ec=\"none\",alpha=0.5,density=False)\n",
    "pt_oe.phi_vector.apply(np.log10).hist(ax=ax,fc=\"b\",ec=\"none\",alpha=0.5,density=False)\n",
    "_ = ax.set_xlabel(\"$log_{10}\\phi$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior phi values are more similar to the prior...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ogs = obs.obgnme.unique()\n",
    "fig,axes = plt.subplots(len(ogs),1,figsize=(10,5*len(ogs)))\n",
    "ogs.sort()\n",
    "for ax,og in zip(axes,ogs):\n",
    "    oobs = obs.loc[obs.obgnme==og,:].copy()\n",
    "    oobs.loc[:,\"time\"] = oobs.time.astype(float)\n",
    "    oobs.sort_values(by=\"time\",inplace=True)\n",
    "    tvals = oobs.time.values\n",
    "    onames = oobs.obsnme.values\n",
    "    [ax.plot(tvals,pr_oe.loc[i,onames].values,\"0.5\",lw=0.1,alpha=0.5) for i in pr_oe.index]\n",
    "    [ax.plot(tvals,pt_oe.loc[i,onames].values,\"b\",lw=0.1,alpha=0.5) for i in pt_oe.index]\n",
    "       \n",
    "    oobs = oobs.loc[oobs.weight>0,:]\n",
    "    tvals = oobs.time.values\n",
    "    onames = oobs.obsnme.values\n",
    "    [ax.plot(tvals,noise.loc[i,onames].values,\"r\",lw=0.1,alpha=0.5) for i in noise.index]\n",
    "    ax.plot(oobs.time,oobs.obsval,\"r-\",lw=2)\n",
    "    ax.set_title(og,loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see more variance in the simulated equivalents to the observations, meaning we arent fitting the historic observations as well...basically, we have only elimiated the extreme prior realizations - we can call this \"light\" conditioning or \"underfitting\"...\n",
    "\n",
    "Let's see what has happened to the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in pst.forecast_names:\n",
    "    plt.figure()\n",
    "    ax = pr_oe.loc[:,forecast].hist(facecolor=\"0.5\",alpha=0.5)\n",
    "    ax = pt_oe.loc[:,forecast].hist(facecolor=\"b\",alpha=0.5)\n",
    "    \n",
    "    ax.set_title(forecast)\n",
    "    fval = pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([fval,fval],ax.get_ylim(),\"r-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now things are getting interesting - the posterior is covering the truth...success?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d91d695e32284e5f4db43d0a55a7ffe722d99eb6050b5b06eff0d966e4449445"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

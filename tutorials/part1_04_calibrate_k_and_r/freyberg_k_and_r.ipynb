{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Match Freyberg using K and Recharge\n",
    "\n",
    "This notebook continues where the `freyberg_k.ipynb` notebook left off. In the previous notebook we calibrated the Freyberg model by adjusting a single parameter - `hk`. We were able to obtain excelent fits with measured heads, and _aparently_ forecast uncertainties were very very low. This was of course __wrong__, as we will see over the course of the next few tutorials.\n",
    "\n",
    "In this tutorial we introduce the concepts of non-uniqueness and parameter correlation. We will repeat the same calibration and uncertainty analysis but with two adjustable parameters - hydraulic conductivity (`hk`) and recharge (`rch0`). \n",
    "\n",
    "In the previous tutorial, recharge parameters were fixed. Remember that when a parameter is fixed (e.g. not adjustable during calibration or uncertainty analysis), this implies that it is perfectly known. Rarely, if ever, is a parameter value perfectly known. Recharge in particular. Recharge is hard to measure in the field and diffcult to upscale to a model domain. It is never perfectly known and should be included in the parameter estimation process. Let's get to it.\n",
    "\n",
    "### Admin\n",
    "We have provided some pre-cooked PEST dataset files, wraped around the modified Freyberg model. This is the same dataset introduced in the \"freyberg_pest_setup\" and \"freyberg_k\" notebooks. \n",
    "\n",
    "The functions in the next cell import required dependencies and prepare a folder for you. This folder contains the model files and a preliminary PEST setup. Run the cells, then inspect the new folder named \"freyberg_k\" which has been created in your tutorial directory. (Just press `shift+enter` to run the cells). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "import shutil\n",
    "\n",
    "sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "pyemu.plot_utils.font =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing original model files\n",
    "org_d = os.path.join('..', '..', 'models', 'monthly_model_files_1lyr_newstress')\n",
    "# a dir to hold a copy of the org model files\n",
    "tmp_d = os.path.join('freyberg_mf6')\n",
    "if os.path.exists(tmp_d):\n",
    "    shutil.rmtree(tmp_d)\n",
    "shutil.copytree(org_d,tmp_d)\n",
    "# get executables\n",
    "hbd.prep_bins(tmp_d)\n",
    "# get dependency folders\n",
    "hbd.prep_deps(tmp_d)\n",
    "# run our convenience functions to prepare the PEST and model folder\n",
    "hbd.prep_pest(tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder - the modified-Freyberg model\n",
    "Just a quick reminder of what the model looks like and what we are doing. \n",
    "\n",
    "It is a one-layer model. A river runs north-south, represented with the SFR package (green cells in the figure). On the southern border there is a GHB (cyan cells). No-flow cells are shown in black. Pumping wells are shown with red cells. \n",
    "\n",
    "Time-series of measured heads are available at the locations marked with black X's. River flux is also measured at three locations (headwater, tailwater and gage; not displayed).\n",
    "\n",
    "The simulation starts with a steady state stress period, followed by twelve transient stress periods. These represent the historic period, for which measured data are available.\n",
    "\n",
    "A subsequent twelve transient stress periods representing a period in the future. Modelling is undertaken to assess selected forecasts during the simulated period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.plot_freyberg(tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PEST Control File\n",
    "\n",
    "You may  wish to explore the `freyberg_mf6` folder which has been created in the tutorial directory. In it you will find a PEST control file named `freyberg.pst`.\n",
    "\n",
    "Let's use `pyemu` to load the PEST control file and check some details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(tmp_d, 'freyberg.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what parameters are listed in the control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.par_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these are adjustable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.adj_par_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So only `hk1` is adjustable. We want to make `rch0` adjustable as well. (`rch0` is a factor by which mean historical recharge is multiplied.)\n",
    "\n",
    "We can do so by chaging the parameter transfrom in the `parameter data` section of the control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `partrans` of the `rch0` parameter to `log`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.loc['rch0', 'partrans'] = 'log'\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now re-write the control file with the updated parameter data section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(tmp_d, 'freyberg_k_r.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PEST once, to check everything is copacetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k_r.pst\",cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just check that it worked by loading the control file again and checking results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(tmp_d, 'freyberg_k_r.pst'))\n",
    "assert pst.phi, \"Something ain't right cap'n\"\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, good to go. We can set `NOPTMAX` to 20 and let PEST loose. We are actualy going to do this twice. Once with `hk` and `rch0` adjustable ( `freyberg_k_r.pst` ) and once with only `hk` adjustable (`freyberg_k.pst`). The latter is a repeat of the previous tutorial. We will do it again just so that we can compare outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 20\n",
    "pst.write(os.path.join(tmp_d, 'freyberg_k_r.pst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(tmp_d, 'freyberg.pst'))\n",
    "pst.control_data.noptmax = 20\n",
    "pst.write(os.path.join(tmp_d, 'freyberg_k.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PEST\n",
    "\n",
    "Okay, let's run this thing. \n",
    "\n",
    "Because we call a program from within the Jupyter Notebook you have to look at the terminal window that you used to start the notebook to see the screen report of the run.  So, when executing this next block look at your terminal window to see the run.  It will say \"pestpp-glm analysis complete...\" when finished.\n",
    "\n",
    "> Note: And/or wait until the standard out reports a \"0\" below this next block (=when the run is finished) before going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pestpp on the pst file defined on the import\n",
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k.pst\", cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pestpp on the pst file defined on the import\n",
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k_r.pst\", cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    "\n",
    "PEST writes lots of usefull information to the `*.rec` file. It also outputs a series of other useful files. What outputs are recorded depends on which version of PEST or PEST++ is being used. Here we will use PEST++GLM. The following section will demonstrate usefull information that can be found in some of the outputs. Throughout subsequent tutorials we will address others.\n",
    "\n",
    "### Objective Function\n",
    "First let's look at the measurement objective function (Phi), which is calculated using the sum of squared weighted residuals.  First we'll look at a table, then plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe \"df_obj\" that shows the contents of the pst file casename with the extension .iobj\n",
    "# .iobj = PEST++ output file that has the objective function by iteration \n",
    "df_obj_k = pd.read_csv(os.path.join(tmp_d, \"freyberg_k.iobj\"),index_col=0)\n",
    "df_obj_k_r = pd.read_csv(os.path.join(tmp_d, \"freyberg_k_r.iobj\"),index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the proress in Phi for both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the dataframe that was shown as a table above\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df_obj_k.loc[:,[\"total_phi\",\"model_runs_completed\"]].plot(y='total_phi', ax=ax, label='k')\n",
    "df_obj_k_r.loc[:,[\"total_phi\",\"model_runs_completed\"]].plot(y='total_phi', ax=ax, label='k+r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like giving PEST more \"flexibility\" (i.e. more parmaters) allows it to get a better fit with measured data. (the Phi obtained by `k+r` is lower).\n",
    "\n",
    "### What about the parameter uncertainties? \n",
    "\n",
    "Read in the parameter uncertainty `*.csv` files which PEST++GLM wrote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru_k = pd.read_csv(os.path.join(tmp_d, \"freyberg_k.par.usum.csv\"),index_col=0)\n",
    "df_paru_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru_k_r = pd.read_csv(os.path.join(tmp_d, \"freyberg_k_r.par.usum.csv\"),index_col=0)\n",
    "df_paru_k_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm - Recharge prior uncertainty = 0.00000?  No, it's not 0.0 - recall that when we log-transformed this parameter, so its uncertainty is reported as logarithms.  So, $10^0 = 1$, which is what we see for an initial value in the PEST control file. \n",
    "\n",
    "How does the uncertainty reduction for `hk1` change when `rch0` is included? Its easier to see if we plot them. Here's the posterior and prior standard deviation for the new K+R (left) next the to K only results (right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru_concat = pd.concat([df_paru_k_r,df_paru_k],join=\"outer\",axis=1,keys=[\"k+r\",\"k_only\"])\n",
    "df_paru_concat.sort_index(inplace=True,axis=1)\n",
    "for pname in df_paru_concat.index:\n",
    "    ax = df_paru_concat.loc[pname,(slice(None),(\"prior_stdev\",\"post_stdev\"))].plot(kind=\"bar\")\n",
    "    ax.set_title(pname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn...so `hk1` uncertainty increases if we include `rch0`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts\n",
    "Let's look at the forecast uncertainties. First for the singe parameter, `k` case. \n",
    "Sweet - nice and tight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predu_k = pd.read_csv(os.path.join(tmp_d, \"freyberg_k.pred.usum.csv\"),index_col=0)\n",
    "df_predu_k.loc[:,\"reduction\"] = 100.0 *  (1.0 - (df_predu_k.post_stdev / df_predu_k.prior_stdev))\n",
    "\n",
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_predu_k,subplots=True)\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the 2 parameter case (`k+r`). Let's compare it to the `k`-only run (shown in green in the plot below). Some forecast uncertainties have increased (the distribution is shorter and wider)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predu_k_r = pd.read_csv(os.path.join(tmp_d, \"freyberg_k_r.pred.usum.csv\"),index_col=0)\n",
    "df_predu_k_r.loc[:,\"reduction\"] = 100.0 *  (1.0 - (df_predu_k_r.post_stdev / df_predu_k_r.prior_stdev))\n",
    "\n",
    "i=1\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for forecast in df_predu_k_r.index:\n",
    "    ax = fig.add_subplot(1,4,i)\n",
    "    i+=1\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_predu_k_r.loc[[forecast],:],ax=ax)\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_predu_k.loc[[forecast],:],ax=ax,pt_color='g')\n",
    "    ax.set_title(forecast)\n",
    "    ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...which forecasts are influenced by the ``rch_0`` parameter? The higher and narrower the peak the more certain we are - did the uncertainty decrease or increase when we added the second parameter?\n",
    "\n",
    "Which forecasts had little change? Why do you think that is?\n",
    "\n",
    "And which case (``K`` or ``K+R``) provides the more robust uncertainty estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold up!\n",
    "\n",
    "Look at this slightly modified version of the groundwater governing equation from Anderson et al. (2015) below.  Is this problem well posed? That is, if recharge increased (represented by an increase in $W^*$) *and* at the same time K increased (represented by an increase in q) could they offset each other so that the righthand side stays the same? What is this called? Yeah, that's right: non-uniqueness.\n",
    "\n",
    " \n",
    "  <img src=\"freyberg_k_and_r_files\\GW_GE2.jpg\" style=\"float: center\">\n",
    " \n",
    " \n",
    "Bravo et al. (2002) showed a trough (the \"trough of despair\"!) in the PHI surface when calibrating K and R with only heads:\n",
    " \n",
    "  <img src=\"freyberg_k_and_r_files\\Fig9.11a_bravo_trough.jpeg\" style=\"float: center\">\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the correlation of our two parameters\n",
    "\n",
    "In the next cell we will use `pyemu.Schur` object. (See the \"intro to pyemu\" and \"intro to FOSM\" tutorials for more details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(os.path.join(tmp_d, \"freyberg_k_r.jcb\"))\n",
    "cov = pyemu.Cov(sc.xtqx.x, names=sc.pst.adj_par_names)\n",
    "R = cov.to_pearson()\n",
    "R.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - correlated.  Hill and Tiedeman (2007) suggest that correlation > 0.95 or so is not estimable. Even though estimating both R and K using only head observations is not possible because of this correlation, PEST++ gave you an answer.  \n",
    "\n",
    "So how did PEST++ deal with this intractable correlation? Let's check how paramter values changed throught the PEST run. Parameter values per iteration are recorded in the `freyberg_k_r.ipar` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipar = pd.read_csv(os.path.join(tmp_d, 'freyberg_k_r.ipar'))\n",
    "ipar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the ratio of `hk1` to `rch0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipar.loc[:, 'ratio'] = ipar.rch0 / ipar.hk1\n",
    "ipar.ratio.plot()\n",
    "plt.ylabel('rch0 / hk1')\n",
    "plt.xlabel('iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So PEST++ found a combination of `hk1` and `rch0` that provide an \"optimal\" fit. It then continues to test changes in parameter values; however, it retains the ratio between these correlated parameters. As this results in no improvement of Phi, PEST halts operation (in this case afetr 3 iterations of no improvement).\n",
    "\n",
    "Effectively, PEST has detemrined the optimal ratio of these two parameters. But not necessarily their \"correct\" absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last point\n",
    "\n",
    "Do you believe that the forecast values are optimal, or even defensible?  Should we believe the forecast uncertainty either? Let's again look at the forecasts with the \"Truth\" (dashed black lines in the plot below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_predu_k_r,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    ax.set_ylim(0, ylim[-1])\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes - very much missing the truth. Uncertainty analysis is still \n",
    "## #failing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History match the Freyberg model using a two parameters ``K`` and ``R`` using head and flux observations\n",
    "\n",
    "#### Where are we on the Goldilocks complexity curve? \n",
    "\n",
    "<img src=\"freyberg_k_r_fluxobs_files/Hunt1998_sweetspot.png\" style=\"float: center\">\n",
    "\n",
    "The runs so far were intended to be greatly oversimplified so as to be a starting point for adding complexity. However, when we added just __*one more parameter*__ (for a total of 2 parameters) uncertainty for some forecasts got appreciably __worse__.  And these parameters cover the entire model domain, which is unrealistic for the natural world! Are we past the \"sweet spot\" where we should avoid additional complexity (even if our model looks nothing like reality)?  \n",
    "\n",
    "Adding parameters in and of itself is not the real problem.  Rather, it is adding parameters that influence forecasts but which are unconstrained by observations so that they are free to wiggle and ripple uncertainty to our forcasts.  If observations are added that help constrain the parameters, the forecast observation will be more certain. That is, the natural flip side of adding parameters is constraining them - either with data (first line of defense) or soft-knowledge and problem dimension reduction (SVD).  \n",
    "\n",
    "[Anderson et al. (2015)](https://www.sciencedirect.com/book/9780120581030/applied-groundwater-modeling) suggest that at a minimum groundwater models be history-matched to heads and fluxes.  There is a flux observation in our PEST control file, but it was given zero weight.  Let's see what happens if we leverage flux data in making our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectives for this notebook are to:\n",
    "1) Add a flux observation to the measurement objective function of our Freyberg model\n",
    "2) Explore the effect of adding the observation to history matching, parameter uncertainty, and forecast uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin\n",
    "We have provided some pre-cooked PEST dataset files, wrapped around the modified Freyberg model. This is the same dataset introduced in the \"freyberg_pest_setup\" and \"freyberg_k\" notebooks. \n",
    "\n",
    "The functions in the next cell import required dependencies and prepare a folder for you. This folder contains the model files and a preliminary PEST setup. Run the cells, then inspect the new folder named \"freyberg_mf6\" which has been created in your tutorial directory. (Just press `shift+enter` to run the cells). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import shutil\n",
    "\n",
    "# sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "pyemu.plot_utils.font =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing original model files\n",
    "org_d = os.path.join('..', '..', 'models', 'monthly_model_files_1lyr_newstress')\n",
    "# a dir to hold a copy of the org model files\n",
    "tmp_d = os.path.join('freyberg_mf6')\n",
    "if os.path.exists(tmp_d):\n",
    "    shutil.rmtree(tmp_d)\n",
    "shutil.copytree(org_d,tmp_d)\n",
    "# get executables\n",
    "hbd.prep_bins(tmp_d)\n",
    "# get dependency folders\n",
    "hbd.prep_deps(tmp_d)\n",
    "# run our convenience functions to prepare the PEST and model folder\n",
    "hbd.prep_pest(tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the PEST control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(tmp_d,'freyberg.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, just run PEST++ to repeat the last tutorial. We do this to have access to files for comparison.\n",
    "\n",
    "As we did in the last tutorial, set `rch0` parameter transform to `log` and update NOPTMAX to 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update paramter transform\n",
    "par = pst.parameter_data\n",
    "par.loc['rch0', 'partrans'] = 'log'\n",
    "# update noptmax\n",
    "pst.control_data.noptmax = 20\n",
    "# write\n",
    "pst.write(os.path.join(tmp_d, 'freyberg_k_r.pst'))\n",
    "# run pestpp\n",
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k_r.pst\", cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at all observations in the PEST run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo the observation data\n",
    "pst.observation_data # .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  that's a lot of observations.  Why so many?  Answer:  we are \"carrying\" lots of model outputs that may be of interest to us later __(not just places and times where we have actual measurements)__.  These outputs include forecasts as well as *\"potential\" observation* locations we will use in dataworth analysis (more on that later)\n",
    "\n",
    "But, the calibration only uses observations where you assign weights.  Let's get a listing of just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the output based on non-zero weights\n",
    "pst.observation_data.loc[pst.nnz_obs_names,:] # .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we have only head calibration targets (calhead).  But it is recommended that we calibrate to heads and fluxes.  \n",
    "\n",
    "Let's give the observation ``gage-1`` a non-zero weight.  You can do this in a text editor but we'll do it in the next block and see the report out for convenience. We chose a new weight of 0.05 for this problem, but we'll spend more time on the concepts involved with observation weighting in a later notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[(obs.obgnme==\"gage-1\") & (obs['gage-1'].astype(float)<=3804.5), \"weight\"] = 0.05 #super subjective\n",
    "obs.loc[obs.obgnme==\"gage-1\"] # .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-write and run PEST++:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(tmp_d, 'freyberg_k_r_flxo.pst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k_r_flxo.pst\", cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the results, how did we do with fit (lowering PHI)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r_flxo.iobj\"),index_col=0)\n",
    "df_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Egads!  Our Phi is a bit larger!  Are we moving backwards? Oh wait, we added a new weighted observation, so we can't compare it directly to what we had with only head observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, what did it do to our parameter uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, let's load in the parameter uncerainty from the previous calibration (in which we only used head observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from the old run that had K and R but head-only calibration\n",
    "df_paru_base = pd.read_csv(os.path.join(tmp_d, \"freyberg_k_r.par.usum.csv\"),index_col=0)\n",
    "# echo out the dataframe\n",
    "df_paru_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, and now the new parameter uncertainty from the new calibration run (with added flux observations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r_flxo.par.usum.csv\"),index_col=0)\n",
    "df_paru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these up like before and compare them side by side. Here are the prior (dashed grey lines) and posterior standard deviations (blue is with flux observations; green is with only head observations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs,axes = pyemu.plot_utils.plot_summary_distributions(df_paru,subplots=True)\n",
    "for pname,ax in zip(pst.adj_par_names,axes):\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_paru_base.loc[[pname],:],ax=ax,pt_color=\"g\")\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the blue shaded areas are taller and thinner than the green. This implies that, from an uncertainty standpoint, including the flux observations has helped us learn a lot about the recharge parameter. As recharge and `hk1` are correlated, this has in turn reduced uncertainty in `hk1`. #dividends\n",
    "\n",
    "But, as usual, what about the forecast uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasts\n",
    "\n",
    "Let's look at our forecast uncertainty for both calibration runs. Load the original forecast uncertainties (head observations only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreu_base = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r.pred.usum.csv\"),index_col=0)\n",
    "df_foreu_base.loc[:,\"reduction\"] = 100.0 *  (1.0 - (df_foreu_base.post_stdev / df_foreu_base.prior_stdev))\n",
    "df_foreu_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the version with the flux observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreu = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r_flxo.pred.usum.csv\"),index_col=0)\n",
    "df_foreu.loc[:,\"reduction\"] = 100.0 *  (1.0 - (df_foreu.post_stdev / df_foreu.prior_stdev))\n",
    "df_foreu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right then, let's plot these up together. Again, the original calibration forecast uncertainties are shaded in green. Forecast uncertainties from the version with head + flux observations are shaded in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in pst.forecast_names:\n",
    "    ax1 = plt.subplot(111)\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_foreu.loc[[forecast],:],ax=ax1)\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_foreu_base.loc[[forecast],:],\n",
    "                                             ax=ax1,pt_color='g')       \n",
    "    ax1.set_title(forecast)\n",
    "    plt.show()\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the information in the flux observations has reduced forecast uncertainty significantly for the `headwater`, but not so much for the `tailwater` forecast. So, at first glance we see that the same model/observation data set can make some forecasts better....but not others! i.e. calibration is sometimes worth it, sometimes it isn't.\n",
    "\n",
    "But have we succeeded? Let's plot with the true forecast values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_foreu,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    ax.set_ylim(0,ylim[-1])\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...._sigh_...still not winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold up!\n",
    "\n",
    "Isn't there a major flaw in our approach to uncertainty here? We freed `rch0` (which affects recharge in the calibration period). But we left the recharge in the forecast period (`rch1`) fixed - which is saying we know it perfectly. \n",
    "\n",
    "Damn...Ok...let's repeat all of the above but with `rch1` freed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.loc['rch1', 'partrans'] = 'log'\n",
    "# write\n",
    "pst.write(os.path.join(tmp_d, 'freyberg_k_r_flxo.pst'))\n",
    "# run pestpp\n",
    "pyemu.os_utils.run(\"pestpp-glm freyberg_k_r_flxo.pst\", cwd=tmp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameter uncertainty\n",
    "df_paru_new = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r_flxo.par.usum.csv\"),index_col=0)\n",
    "# get forecast uncertainty\n",
    "df_foreu_new = pd.read_csv(os.path.join(tmp_d,\"freyberg_k_r_flxo.pred.usum.csv\"),index_col=0)\n",
    "df_foreu_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the parameter uncertainties. This time, pink shaded areas are the previous calibration run (with `rch1` fixed), blue is the new run (all parameters freed).\n",
    "\n",
    "The `hk1` and `rch0` parameter uncertainties are the same as before. Note that the `rch1` prior and posterior uncertainty is the same. Which makes sense... the observation data which we have contains no information that informs what recharge will be in the future (well, it might... but let's not get sidetracked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs,axes = pyemu.plot_utils.plot_summary_distributions(df_paru_new,subplots=True)\n",
    "for pname,ax in zip(pst.adj_par_names,axes):\n",
    "    if pname == \"rch1\":\n",
    "        continue\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_paru.loc[[pname],:],ax=ax,pt_color=\"fuchsia\")\n",
    "plt.ylim(0)\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does this new source of uncertainty ripple out to our forecasts? Plot up the forecast uncertainties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs,axes = pyemu.plot_utils.plot_summary_distributions(df_foreu_new,subplots=True)\n",
    "for forecast,ax in zip(sorted(pst.forecast_names),axes):\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_foreu.loc[[forecast],:],ax=ax,pt_color=\"fuchsia\")\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh hello! Forecast uncertainty for the `headwater` and `tailwater` forecasts have increased alot (the `trgw` and `part_time` forecast did as well, but less noticeably). \n",
    "\n",
    "We see that the posterior for most forecasts is increased because of including future recharge uncertainty.  Intuitively, it makes sense because future recharge directly influences water levels and fluxes in the future.  And since calibration (history-matching) can't tell us anything about future recharge, this means there are no data we can collect to reduce this source of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... success? What do you think? At least some truth values are bracketed by the predictions but... _sigh_... some predictions are still way off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_foreu_new,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    ax.set_ylim(0,ylim[-1])\n",
    "figs[0].tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

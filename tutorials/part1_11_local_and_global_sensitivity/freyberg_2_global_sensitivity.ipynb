{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity Analysis (GSA)\n",
    "\n",
    "Sensitivity methods we've looked at so far only evaluate the \"local\" sensitivity at a single set of parameter values.  For example, the Jacobian matrix represents perturbations to a single set of parameter values.  This local view can be a problem in cases when our inverse problem is nonlinear (i.e. most cases), which means the parameter sensitivities can change depending on what the parameter value is. \n",
    "\n",
    "### What if we looked at more than one set of parameter values?\n",
    "\n",
    "In contrast, Global Sensitivity Analyses are statistical approaches that characterize how model parameters affect model outputs over a __wide range__ of acceptable parameter values. GSA aims for greater robustness and information provision than local sensitivity analysis based on partial derivatives of model outputs with respect to model parameters. Because local sensitivity analysis is limited to a single point in parameter space, the information it produces is frequently insufficient to support an understanding of the behaviour of nonlinear models whose outputs depend on complicated and parameter-value-dependent combinations of model parameters.\n",
    "\n",
    "Some GSA methods provide general information about the variability of the sensitivities and have relatively low computational requirements, whereas others provide detailed information on nonlinear behavior and interactions between parameters at the expense of larger computational requirements. For a complete introduction to GSA theory and methods, see [Saltelli et al (2004)](http://www.andreasaltelli.eu/file/repository/SALTELLI_2004_Sensitivity_Analysis_in_Practice.pdf) and [Saltelli et al (2008)](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470725184).\n",
    "\n",
    "\n",
    "[Saltelli et al (2004)](http://www.andreasaltelli.eu/file/repository/SALTELLI_2004_Sensitivity_Analysis_in_Practice.pdf) provide an overview of the \"settings\" in which sensitivity analysis can be usefuly employed. Of these, in an environmental modelling context the following are highlighted:\n",
    "\n",
    "1. Identifying non-influential parameters (also known as \"screening\") is useful in the process of simplifying complex models (or parameterisation schemes). Non-influencial parameters are those that do not influence the model output of interest (whether it be a forecast or the measurement objective function). These are parameters which can be fixed at any given value, without significantly influencing the output of interest. If necessary, they can be omitted from model design or parameter estimation, in an effort to reduce computational burden.\n",
    "\n",
    "2. Identifying parameters, and the interactions between parameters, which are important for a forecast of interest. This is perhaps one of the most common uses of sensitivity analysis. Assuming that all uncertain parameters are susceptible to determination (at the same cost per parameter). A sensitivity analysis can aid in identifying the parameter that is most deserving of better experimental measurement in order to reduce the forecast uncertainty the most.\n",
    "\n",
    "3. Mapping parameter-to-output response. Often decision-support modelling is interested in avoiding an undesired outcome for some forecast of interest. Sensitivity analysis can be employed to assess which parameters (or parameter combinations) are most responsible for producing output in the region of interest. In other words, which parameter (and parameter values) are most likely to result in a \"bad thing\" happening? This can become useful in a hypothesis-testing workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSA with PEST++\n",
    "\n",
    "[PEST++SEN](https://github.com/usgs/pestpp/blob/master/documentation/pestpp_users_manual.md#7-pestpp-sen) currently supports two GSA meth­ods. These are:\n",
    "\n",
    " - the __Method of Morris__ ([Morris](https://abe.ufl.edu/Faculty/jjones/ABE_5646/2010/Morris.1991%20SA%20paper.pdf), 1991), with extensions proposed by [Campolongo et al.](https://publications.jrc.ec.europa.eu/repository/handle/JRC31319) (2005), and\n",
    " - the __Method of Sobol__ ([Sobol](http://www.andreasaltelli.eu/file/repository/Sobol_2001.pdf), 2001).\n",
    "\n",
    "In this tutorial we'll focus on the __Method of Morris__ because it is computationally more efficient. But this efficiency comes with a tradeoff: the Method of Morris only provides estimates of the _mean_ and _variance_ of the sensitivity distribution for each parameter. Because of the lack of complete description of the parameter nonlinearity and interactions between parameters, the Method of Morris can be used as a _screening-level_ tool to identify the most important parameters for the observations tested. This screening can be followed by application of a more comprehensive tool, such as the Method of Sobol, which further characterizes the effects of parameter nonlinearity and inter-parameter interactions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method of Morris\n",
    "\n",
    "As described in Saltelli et al (2004), the guiding philosophy of the Morris method is to determine which parameters may be considered to have effects which are (a) negligible, (b) linear and additive, or (c) non-linear or correlated with other parameters. The experimental plan proposed by Morris is composed of individually randomised 'one-at-a-time' experiments; the impact of changing one factor at a time is evaluated in turn. The Method of Morris is referred to as a “one-at-a-time” method because each parameter is perturbed sequentially to compute sensitivities - making it ideally suited for parallel computing. \n",
    "\n",
    "> Many parameters evaluated = lots of computer time. Luckily we can use [PEST++SEN](https://github.com/usgs/pestpp/blob/master/documentation/pestpp_users_manual.md#7-pestpp-sen) to run GSA in parallel. \n",
    "\n",
    "The method samples the sensitivity of a given parameter at several locations over the range of reasonable parameter space (__defined by the parameter bounds in the PEST Control file__) and then provides two measures of parameter sensitivity: the mean (__μ__) and the standard deviation (__σ__) of the resulting sensitivity distribution. The mean, __μ__, captures the overall effect of a parameter on the model output of interest; the standard deviation, __σ__, measures a parameter’s sensitivity across the range of acceptable parameter values, this being an indicator of how nonlinear a given parameter is and (or) how the parameter interacts with other parameters. It is important to note that the Method of Morris __cannot distinguish__ between parameter nonlinearity and parameter interactions because only the standard deviation of parameter sensitivity is available. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Current Tutorial\n",
    "\n",
    "In this notebook we will undertake GSA of the Freyberg model that employs pilot points as a parameterisation device. We will use the same model and PEST setup as in the \"freyberg_1_local_sensitivity\" tutorial ntoebook, and employ the Method of Morris.\n",
    "\n",
    "### Admin\n",
    "\n",
    "First the usual admin of preparing folders and constructing the model and PEST datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import shutil\n",
    "\n",
    "# sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "pyemu.plot_utils.font =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing original model files\n",
    "org_d = os.path.join('..', '..', 'models', 'monthly_model_files_1lyr_newstress')\n",
    "# a dir to hold a copy of the org model files\n",
    "working_dir = os.path.join('freyberg_mf6')\n",
    "if os.path.exists(working_dir):\n",
    "    shutil.rmtree(working_dir)\n",
    "shutil.copytree(org_d,working_dir)\n",
    "# get executables\n",
    "hbd.prep_bins(working_dir)\n",
    "# get dependency folders\n",
    "hbd.prep_deps(working_dir)\n",
    "# run our convenience functions to prepare the PEST and model folder\n",
    "hbd.prep_pest(working_dir)\n",
    "# convenience function that builds a new control file with pilot point parameters for hk\n",
    "hbd.add_ppoints(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the `pst` control file\n",
    "\n",
    "Let's double check what parameters we have in this version of the model using `pyemu` (you can just look in the PEST control file too.).\n",
    "\n",
    "We have adjustable parameters that control SFR inflow rates, well pumping rates, hydraulic conductivity and recharge rates. Recall that by setting a parameter as \"fixed\" we are stating that we know it perfectly (should we though...?). Currently fixed parameters include porosity and future recharge.\n",
    "\n",
    "For the sake of this tutorial, and as we did in the \"local sensitivity\" tutorial, let's set all the parameters free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_name = \"freyberg_pp.pst\"\n",
    "# load the pst\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "#update parameter data\n",
    "par = pst.parameter_data\n",
    "#update paramter transform\n",
    "par.loc[:, 'partrans'] = 'log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite the control file!\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity\n",
    "\n",
    "Unlike in the local sensitivity tutorial, we are no longer reliant on the existence of a Jacobian matrix. \n",
    "\n",
    "However, to implement the Method of Morris we need to run the model a certain number of times for each adjustable parameter.   By default (no extra settings), PEST++SEN will run the Method of Morris with 4 discretization points for each parameter, plus the 4 new starting points from the intial conditions (4 runs). Effectively this will take 4 times as much computational time as calculating a Jacobian matrix would. \n",
    "\n",
    "Fortunately, we can run it in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, make sure to specify the number of agents to use. This value must be assigned according to the capacity of your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the master directory\n",
    "m_d='master_gsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(working_dir, # the folder which contains the \"template\" PEST dataset\n",
    "                            'pestpp-sen', # the PEST software version we want to run\n",
    "                            pst_name, # the control file to use with PEST\n",
    "                            num_workers=num_workers, # how many agents to deploy\n",
    "                            worker_root='.', # where to deploy the agent directories; relative to where python is running\n",
    "                            master_dir=m_d, # the manager directory\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSA results\n",
    "\n",
    "Let's look at a table and plot of the GSA results.  In this case we are looking at the mean sensitivity, and the standard deviation of the sensitivity as we change the starting value in the parameter space.  \n",
    "\n",
    "> If the __mean sensitivity is high__ it shows that parameter has higher sensitivity across the parameter space.  \n",
    "\n",
    ">If the __standard deviation is low__, then the linear assumptions of FOSM holds (that is, the sensitivity is similar regardless of parameter value).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Sensitvities\n",
    "\n",
    "PES++SEN has written an output file with the extension `*.msn`. This file lists method of Morris outputs (μ, μ* and σ) for each adjustable parameter. The model-generated quantity for which these provide sensitivity measures is the objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(m_d,pst_name.replace(\".pst\",\".msn\")), index_col='parameter_name')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.sen_mean_abs>1e-6,:]\n",
    "df.loc[:,[\"sen_mean_abs\",\"sen_std_dev\"]].plot(kind=\"bar\", figsize=(13,4))\n",
    "#ax = plt.gca()\n",
    "#ax.set_ylim(1,ax.get_ylim()[1]*1.1)\n",
    "plt.yscale('log');\n",
    "fig,ax = plt.subplots(1,1,figsize=(13,8))\n",
    "tmp_df = df\n",
    "ax.scatter(tmp_df.sen_mean_abs,tmp_df.sen_std_dev,marker=\"^\",s=20,c=\"r\")\n",
    "tmp_df = tmp_df.iloc[:8]\n",
    "for x,y,n in zip(tmp_df.sen_mean_abs,tmp_df.sen_std_dev,tmp_df.index):\n",
    "    ax.text(x,y,n)\n",
    "mx = max(ax.get_xlim()[1],ax.get_ylim()[1])\n",
    "mn = min(ax.get_xlim()[0],ax.get_ylim()[0])\n",
    "ax.plot([mn,mx],[mn,mx],\"k--\")\n",
    "ax.set_ylim(mn,mx)\n",
    "ax.set_xlim(mn,mx)\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"$\\\\sigma$\")\n",
    "ax.set_xlabel(\"$\\\\mu^*$\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where mean absolute sensitivity ($μ^*$) - blue bars - is large, shows that the parameter is sensitive across parameter space. The parameters `rch0` and `strinf` stand out. This is logical, as it is reasonable that they both have a singificant control on the systems' water budget (reminder: these parameters are global recharge and stream inflow rates). \n",
    "\n",
    "Other parameters which are notable are `ne1` (porosity) and `rch1` (recharge in the future). Sensitivities for these are nonexistent. Is this reasoanble? In this case - yes. Why? Because we have no observations in the calibration dataset that inform these parameters. We have no measurements in the future which might provide information on recharge (because it is the future...), and we have no measurements of transport or flow velocities which might inform porosity.\n",
    "\n",
    "This means that, from a __parameter estimation__ perspective, these two parameter groups are not important. If we are concerned with computational cost, we could potentially omit them from parameter esitmation. However! These results tell us nothing about their importance from a forecast perspective. So we may still need to include them during uncertainty analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation ($σ$) - orange bars - is large everywhere. This is a sign that parameters are suffering from:\n",
    "\n",
    "1. nonlinearity and/or\n",
    "2. correlation/interaction with other parameters\n",
    "\n",
    "The Method of Morris cannot distinguish between the two! Recall from the local sensitivity tutorial that we saw many of these parameters were correlated - but not all!\n",
    "\n",
    "So, if nonlinearity is an issue - should we be using FOSM to undertake uncertainty analysis? Perhaps not, as it relies on the assumption of a linear relation between parameter changes and model output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Sensitivities\n",
    "\n",
    "Decision-support modelling always brings us back to our forecasts. As discussed above, identifying parameters (and the interactions between parameters) which are important for a forecast of interest can aid decision-support modelling design. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PES++SEN has written an output file with the extension `*.mio`. This file records μ, μ* and σ for all model outputs featured in the “observation data” section of the PEST control file.\n",
    "\n",
    "We can load it and inspect sensitivities for our forecast observations. The cell below produces bar-plots  displaying parameter μ* and σ for each forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sen = pd.read_csv(os.path.join(m_d,pst_name.replace(\".pst\",\".mio\")),skipinitialspace=True)\n",
    "for forecast in pst.forecast_names:\n",
    "    tmp_df = df_pred_sen.loc[df_pred_sen.observation_name==forecast].sort_values(by='sen_mean_abs', ascending=False)\n",
    "    tmp_df.plot(x=\"parameter_name\",y=[\"sen_mean_abs\",\"sen_std_dev\"],kind=\"bar\", figsize=(13,2.5))\n",
    "    plt.title(forecast)\n",
    "    plt.yscale('log');\n",
    "    fig,ax = plt.subplots(1,1,figsize=(13,8))\n",
    "    ax.scatter(tmp_df.sen_mean_abs,tmp_df.sen_std_dev,marker=\"^\",s=20,c=\"r\")\n",
    "    tmp_df = tmp_df.iloc[:8]\n",
    "    for x,y,n in zip(tmp_df.sen_mean_abs,tmp_df.sen_std_dev,tmp_df.parameter_name):\n",
    "        ax.text(x,y,n)\n",
    "    mx = max(ax.get_xlim()[1],ax.get_ylim()[1])\n",
    "    mn = min(ax.get_xlim()[0],ax.get_ylim()[0])\n",
    "    ax.plot([mn,mx],[mn,mx],\"k--\")\n",
    "    ax.set_ylim(mn,mx)\n",
    "    ax.set_xlim(mn,mx)\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(\"$\\\\sigma$\")\n",
    "    ax.set_xlabel(\"$\\\\mu^*$\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, different forecasts are sensitive to different parameters. Note, for example, that the `part_time` (particle travel time) forecast is sensitive to `ne1` (porostity) parameters, however none of the other forecasts are. Almost all forecasts are sensitive to recharge (`rch0` and `rch1`), and so on. By ranking sensitivities in this fashion, we can identify which parameters to focus on to reduce forecast uncertainty. We can also identify parameters which can be omitted (or \"simplified\"), if they have little or no effect on the forecast of interest (e.g. porosity on the `headwater` forecast).\n",
    "\n",
    "As we saw above for parameters, once again σ is very high (for almost all parameters...). This suggests either non-linearity and/or parameter interactions. Relying on linear methods for uncertainty analysis is therefore compromised. Ideally we should employ non-linear methods, as will be discussed in the subsequent tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

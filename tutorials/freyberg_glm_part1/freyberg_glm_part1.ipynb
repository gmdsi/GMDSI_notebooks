{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling a Jacobian Matrix\n",
    "\n",
    "This notebook is an optional, but recommended, first step for a workflow that implements linear uncertainty analysis (i.e. FOSM), data worth analysis and highly-parameterized regularised inversion (i.e. calibration). It will be realitvely short, but provides the foundation for subsequet tutorials. \n",
    "\n",
    "Here, we are going to calculate a base Jacobian. In other words, we are going to calculate partial derivatives of model outputs with respect to (adjustable) model parameters. Or \"how much each observation value changes for a change in each parameter value\".  These partial derivatives (or *sensitivity coefficients*) are fundamental for the implementation of inversion and for linear uncertainty analysis. They form a two-dimensional array of values with as many rows as observations and as many columns as parameters. This array is commonly known as the **Jacobian matrix**. \n",
    "\n",
    "PEST and PEST++GLM (as well as some other PEST++ versions) calculate and record a Jacobian as part of normal execution. They do so by running \"the model\" as many times as there are adjustable parameters. Each time, a parameter is adjusted and the corresponding effects on all observations are recorded. These are used to fill in the Jacobian. Once the Jacobian is calculated, the derivative information is used to identify parameter changes that will improve the fit between model outputs and measured data. These are used to update the \"calibrated\" parameter set. Due to the nonlinear nature of groundwater inverse problems, this process may need to be repeated numerous times during calibration. As you can imagine, if there are many adjustable parameters, this process can take up a lot of computation time. \n",
    "\n",
    "Filling the Jacobian is perhaps the main computational cost of derivative-based optimisation methods such as are implemented in PEST and PEST++GLM. \n",
    "\n",
    "However, this cost is often qorth it as a Jacobian matrix has many uses. Many of these uses are as important as the model calibration process itself. Hence it is not unusual for PEST or PEST++GLM to be run purely for the purpose of filling a Jacobian matrix (as we will do here). \n",
    "\n",
    "Uses to which a Jacobian matrix may be put include the following:\n",
    " - Examination of local sensitivities of model outputs to parameters and/or decision variables.\n",
    " - Giving PEST or PEST++GLM a “head start” in calibrating a model by providing it with a pre-calculated Jacobian matrix to use in its first iteration. For PEST++GLM this is achieved through use of the `base_jacobian()` control variable, as we will demonstrate in a subsequent tutorial.\n",
    " - To support the many types of linear analysis implemented by utility programs supplied with PEST, and functions provided by `pyEMU`; these calculate\n",
    "    - parameter identifiability;\n",
    "    - parameter and predictive uncertainty;\n",
    "    - parameter contributions to predictive uncertainty;\n",
    "    - data worth;\n",
    "    - the effects of model defects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Admin\n",
    "\n",
    "Start off with the usual loading of dependencies and preparing model and PEST files. We will be continuing to work with the MODFLOW6 modified-Freyberg model (see \"freyberg intro to model\" notebook), and the high-dimensional PEST dataset prepared in the \"freyberg pstfrom pest setup\" and \"freyberg obs and weights\" notebooks. \n",
    "\n",
    "For the purposes of this notebook, you do not require familiarity with previous notebooks (but it helps...). \n",
    "\n",
    "Simply run the next few cells by pressing `shift+enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pyemu\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# import pre-prepared convenience functions\n",
    "import herebedragons as hbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to the PEST dataset template folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy across pre-prepared model and PEST files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied from:..\\..\\models\\freyberg_obs_and_weights\n",
      "Files copied to:freyberg6_template\n"
     ]
    }
   ],
   "source": [
    "# use the convenience function to get the pre-preprepared PEST dataset;\n",
    "# this is the same dataset consutructed in the \"obs and weights\" tutorial\n",
    "hbd.dir_cleancopy(org_d=os.path.join('..','..', 'models','freyberg_obs_and_weights'), \n",
    "                new_d=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inspect the PEST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the PEST control file as a `Pst` object. We are going to use the PEST control file that was created in the \"freyberg obs and weights\" tutorial. This control file has observations weighted so that each observation groups has an equal contribution to the objective function. This does not matter for the current tutorial, but is to maintain continuity for subsequent tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d, 'freyberg_wv.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a quick parameter summary table as a reminder of what we have in our control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>transform</th>\n",
       "      <th>count</th>\n",
       "      <th>initial value</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "      <th>standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ghbcond_cn</th>\n",
       "      <td>ghbcond_cn</td>\n",
       "      <td>log</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghbcond_gr</th>\n",
       "      <td>ghbcond_gr</td>\n",
       "      <td>log</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghbhead_cn</th>\n",
       "      <td>ghbhead_cn</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghbhead_gr</th>\n",
       "      <td>ghbhead_gr</td>\n",
       "      <td>none</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npf_k33_layer1_cn</th>\n",
       "      <td>npf_k33_layer1_cn</td>\n",
       "      <td>log</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.69897</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sto_sy_layer1_cn</th>\n",
       "      <td>sto_sy_layer1_cn</td>\n",
       "      <td>log</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.69897</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sto_sy_layer1_gr</th>\n",
       "      <td>sto_sy_layer1_gr</td>\n",
       "      <td>log</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.69897</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sto_sy_layer1_pp</th>\n",
       "      <td>sto_sy_layer1_pp</td>\n",
       "      <td>log</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.69897</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wel_cst</th>\n",
       "      <td>wel_cst</td>\n",
       "      <td>log</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30103</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.11928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wel_grd</th>\n",
       "      <td>wel_grd</td>\n",
       "      <td>log</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30103</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.11928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                type transform  count initial value  \\\n",
       "ghbcond_cn                ghbcond_cn       log      1             0   \n",
       "ghbcond_gr                ghbcond_gr       log     30             0   \n",
       "ghbhead_cn                ghbhead_cn      none      1            10   \n",
       "ghbhead_gr                ghbhead_gr      none     30            10   \n",
       "npf_k33_layer1_cn  npf_k33_layer1_cn       log      1             0   \n",
       "...                              ...       ...    ...           ...   \n",
       "sto_sy_layer1_cn    sto_sy_layer1_cn       log      1             0   \n",
       "sto_sy_layer1_gr    sto_sy_layer1_gr       log    706             0   \n",
       "sto_sy_layer1_pp    sto_sy_layer1_pp       log     32             0   \n",
       "wel_cst                      wel_cst       log     25             0   \n",
       "wel_grd                      wel_grd       log    150             0   \n",
       "\n",
       "                  lower bound upper bound standard deviation  \n",
       "ghbcond_cn                 -1           1                0.5  \n",
       "ghbcond_gr                 -1           1                0.5  \n",
       "ghbhead_cn                  8          12                  1  \n",
       "ghbhead_gr                  8          12                  1  \n",
       "npf_k33_layer1_cn    -0.69897     0.69897           0.349485  \n",
       "...                       ...         ...                ...  \n",
       "sto_sy_layer1_cn     -0.69897     0.69897           0.349485  \n",
       "sto_sy_layer1_gr     -0.69897     0.69897           0.349485  \n",
       "sto_sy_layer1_pp     -0.69897     0.69897           0.349485  \n",
       "wel_cst              -0.30103    0.176091            0.11928  \n",
       "wel_grd              -0.30103    0.176091            0.11928  \n",
       "\n",
       "[111 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our parameterisation is quite comprehensive, with pilot points and grid based (e.g. cell-by-cell) parameters. \n",
    "\n",
    "Let's recall how many adjustable parameters we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a lot! How long does the model take to run? Even if it is well under a minute, that can quickly add up. Just to illustrate, let's chekc how long it takes our forwrd run to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.174291099999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# execute the model forward_run.py script\n",
    "pyemu.os_utils.run('python forward_run.py', cwd=t_d)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, very roughly, we can estimate how long it will take to fill in a Jacobian matrix. Let's assume we will be running this in parallel with as many agents as we have cores (update `number_of_cpu_cores` according to what you have at your disposal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hours to fill a jacobian:22.84978046566111\n"
     ]
    }
   ],
   "source": [
    "number_of_cpu_cores = 5\n",
    "\n",
    "print(f'Number of hours to fill a jacobian:{pst.npar_adj * elapsed / 60/60 / number_of_cpu_cores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you have many many CPU's at hand, that's still going to be pretty long despite the relatively fast model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Good-Bye High-Dimensional Parameterisation!\n",
    "\n",
    "As previously discussed, the computational cost of conventional model calibration (attained through\n",
    "adjustment of a single parameter field using partial derivatives calculated using finite parameter\n",
    "differences) increases with the number of adjustable parameters. This imposes pragmatic limits on the number of adjustable parameters we can have.\n",
    "\n",
    "We are limited by compute power (e.g. how many parallel model runs can we deploy) and how long each model takes to run. At the end of the day, it will be project time and cost constraints that will pose hard limits on what is acceptible. \n",
    "\n",
    "So here comes the painfull part: we can't use these 10's of thousands of parameters. We are going to have to set many of them as \"fixed\" (e.g. no longer adjustable). We do this by changing the parameter transform value in the `* parameter data` section (e.g. the \"partrans\" column in `pst.parameter_data`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set all the grid scale parameters as fixed, with the exception of the SFR inflow parameters. That will sort a large amount. The cost is we lose the ability to capture the effects of small-scale heterogeneity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say goodbye to grid-scale pars\n",
    "gr_pars = par.loc[par.pargp.apply(lambda x: \"gr\" in x and \"sfr\" not in x),\"parnme\"]\n",
    "par.loc[gr_pars,\"partrans\"] = \"fixed\"\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix all recharge pilot point parameters. We will at least still have the layer-scale parameters for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rch_pp = [i for i in pst.adj_par_groups if i.startswith('rch') and i.endswith('_pp') ]\n",
    "par.loc[par['pargp'].isin(rch_pp),\"partrans\"] = \"fixed\"\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also fix pilot point parameters for storage, and for vertical conductivity ratio in layer 1 and 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_grps = [ #'sto_ss_layer3_pp',\n",
    "            'sto_ss_layer2_pp',\n",
    "            #'sto_sy_layer1_pp', \n",
    "            'npf_k33_layer1_pp',\n",
    "            'npf_k33_layer3_pp',\n",
    "            ]\n",
    "par.loc[par.pargp.apply(lambda x: x in fi_grps),\"partrans\"] = \"fixed\"\n",
    "\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's check that estimate of run time again...hmm...a bit more manageable. Of course, the cost of this has been a loss of flexibility in our parameterisation scheme. This means we are potentialy less able to fit historical data...but worse, we are also less able to capture the effect of uncertianty from these fixed parameters on model forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hours to fill a jacobian:0.17072862827777774\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of hours to fill a jacobian:{pst.npar_adj * elapsed / 60/60 / number_of_cpu_cores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, if we are happy (#sadface) with the number of parameters, we can move on.\n",
    "\n",
    "To instruct PEST or PEST++GLM to only calculate the Jacobian and then stop, we assign a value of -1 or -2 to the NOPTMAX control value. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to go. Let's re-write the control file. We will record this with a new name: `freyberg_pp.pst`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noptmax:-1, npar_adj:587, nnz_obs:920\n"
     ]
    }
   ],
   "source": [
    "pst.write(os.path.join(t_d,\"freyberg_pp.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run PEST++GLM\n",
    "\n",
    "Alright! Let's run this thing!\n",
    "\n",
    "As we saw in the \"freyberg prior monte carlo\" notebook, we can use `pyemu` to deploy PEST in parallel. \n",
    "\n",
    "To speed up the process, you will want to distribute the workload across as many parallel agents as possible. Normally, you will want to use the same number of agents (or less) as you have available CPU cores. Most personal computers (i.e. desktops or laptops) these days have between 4 and 10 cores. Servers or HPCs may have many more cores than this. Another limitation to keep in mind is the read/write speed of your machines disk (e.g. your hard drive). PEST and the model software are going to be reading and writting lots of files. This often slows things down if agents are competing for the same resources to read/write to disk. (It also wears through SSD drives...)\n",
    "\n",
    "The first thing we will do is specify the number of agents we are going to use.\n",
    "\n",
    "# Attention!\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 5 # update according to your available resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then specify the folder in which the PEST manager will run and record outcomes. It should be different form the `t_d` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = os.path.join('master_glm_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using `pestpp-glm`. Run it by pressing `shift+enter`.\n",
    "\n",
    "If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see `pestpp-glm`'s progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. `pyemu` will remove them when PEST finishes running.\n",
    "\n",
    "This run should take a while to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking `pestpp-glm` from communicating with the agents (this is a common problem!).\n",
    "\n",
    "If you do not wish to run PEST yourself for this tutorial, you do not have to. All necessary files for subsequent tutorials will be provided. That being said, it may worth doing simply to see how the mechanics work and to become familiar with PEST output files....and not mention as a way to feel a foreshadowing of the pain of slow running models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-glm\",\"freyberg_pp.pst\",num_workers=num_workers,worker_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d91d695e32284e5f4db43d0a55a7ffe722d99eb6050b5b06eff0d966e4449445"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('gmdsitut')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

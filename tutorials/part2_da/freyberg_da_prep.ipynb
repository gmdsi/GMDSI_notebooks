{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for sequential data assimilation\n",
    "\n",
    "### 1. The modified Freyberg PEST dataset\n",
    "\n",
    "The modified Freyberg model is introduced in another tutorial notebook (see \"freyberg intro to model\"). The current notebook picks up following the \"freyberg psfrom pest setup\" notebook, in which a high-dimensional PEST dataset was constructed using `pyemu.PstFrom`. You may also wish to go through the \"intro to pyemu\" notebook beforehand.\n",
    "\n",
    "The next couple of cells load necessary dependencies and call a convenience function to prepare the PEST dataset folder for you. This is the same dataset that was constructed during the \"freyberg pstfrom pest setup\" tutorial. Simply press `shift+enter` to run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pyemu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "import flopy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# import pre-prepared convenience functions\n",
    "import herebedragons as hbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: if we move the obsvals and weights process to a sep notebook, \n",
    "# we need to also check that it has been executed. We could set an \n",
    "# \"observed\" column in the obs data to indicate that we have set obs vals and weights?\n",
    "\n",
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_da_template')\n",
    "\n",
    "org_t_d = os.path.join(\"..\",\"part2_pstfrom_pest_setup\",\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_pstfrom_pest_setup/freyberg_pstfrom_pest_setup.ipynb' notebook\")\n",
    "\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "shutil.copytree(org_t_d,t_d)\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several modifications we need to make to both the model and pest interface in order to go from batch estimation to sequential estimation.  First, we need to make the model a single stress period model - PESTPP-DA will take control of the advancement of simulation time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(t_d,\"freyberg6.tdis\"),'w') as f:\n",
    "    f.write(\"# new tdis written hastily at {0}\\n]\\n\".format(datetime.now()))\n",
    "    f.write(\"BEGIN options\\n  TIME_UNITS days\\nEND options\\n\\n\")\n",
    "    f.write(\"BEGIN dimensions\\n  NPER 1\\nEND dimensions\\n\\n\")\n",
    "    f.write(\"BEGIN perioddata\\n  1.0  1 1.0\\nEND perioddata\\n\\n\")\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just make sure we havent done something dumb (er than usual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"mf6\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the hard part\n",
    "\n",
    "First, let's assign cycle numbers to the time-varying parameters and their template files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"freyberg_mf6.pst\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pst.model_input_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"cycle\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = df.loc[df.pest_file.apply(lambda x: \"sfr\" in x and \"cond\" not in x),:]\n",
    "sfrdf.loc[:,\"inst\"] = sfrdf.pest_file.apply(lambda x: int(x.split(\"inst\")[1].split(\"_\")[0]))\n",
    "sfrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[sfrdf.index,\"cycle\"] = sfrdf.inst.values\n",
    "df.loc[sfrdf.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weldf = df.loc[df.pest_file.str.contains('wel'),:]\n",
    "weldf.loc[:,\"cycle\"] = weldf.pest_file.apply(lambda x: int(x.split(\"inst\")[1].split(\"_\")[0]))\n",
    "weldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rchdf = df.loc[df.pest_file.apply(lambda x: \"rch\" in x and \"tcn\" in x),:]\n",
    "rchdf.loc[:,\"cycle\"] = rchdf.pest_file.apply(lambda x: int(x.split(\"tcn\")[0].split(\"_\")[-1])-1)\n",
    "rchdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.loc[:,\"cycle\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = par.loc[par.parnme.str.contains(\"wel\"),:]\n",
    "wpar.loc[:,\"cycle\"] = wpar.inst.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spar = par.loc[par.parnme.apply(lambda x: \"sfr\" in x and \"cond\" not in x),:]\n",
    "spar.loc[:,\"cycle\"] = spar.inst.astype(int)\n",
    "spar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpar = par.loc[par.parnme.apply(lambda x: \"rch\" in x and \"tcn\" in x),:]\n",
    "rpar.loc[:,\"cycle\"] = rpar.parnme.apply(lambda x: int(x.split(\"tcn\")[0].split(\"_\")[-1])-1)\n",
    "rpar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add a special parameter that will be used to control the length of the stress period that the single-stress-period model will simulate.  As usual, we do this with a template file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(t_d,\"freyberg6.tdis.tpl\"),'w') as f:\n",
    "    f.write(\"ptf ~\\n\")\n",
    "    f.write(\"# new tdis written hastily at {0}\\n]\\n\".format(datetime.now()))\n",
    "    f.write(\"BEGIN options\\n  TIME_UNITS days\\nEND options\\n\\n\")\n",
    "    f.write(\"BEGIN dimensions\\n  NPER 1\\nEND dimensions\\n\\n\")\n",
    "    f.write(\"BEGIN perioddata\\n  ~  perlen  ~  1 1.0\\nEND perioddata\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_parameters(os.path.join(t_d,\"freyberg6.tdis.tpl\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[\"perlen\",\"partrans\"] = \"fixed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `perlen` needs to change over cycles, we can use a parameter cycle table rather than making a duplicate template file and `perlen` parameter for each cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=org_t_d,load_only=[\"dis\"])\n",
    "org_perlen = sim.tdis.perioddata.array[\"perlen\"]\n",
    "org_perlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"perlen\":org_perlen},index=np.arange(org_perlen.shape[0]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(t_d,\"par_cycle_table.csv\"))\n",
    "pst.pestpp_options[\"da_parameter_cycle_table\"] = \"par_cycle_table.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the observation data - yuck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"freyberg_mp.mpend.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"sfr.tdiff.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.drop_observations(os.path.join(t_d,\"heads.tdiff.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pst.drop_observations(os.path.join(t_d,\"heads.csv.ins\"),pst_path=\".\")\n",
    "#sdf = pst.drop_observations(os.path.join(t_d,\"sfr.csv.ins\"),pst_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pst.model_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = None\n",
    "for ins_file in pst.model_output_data.pest_file:\n",
    "    if ins_file.startswith(\"hdslay\"):\n",
    "        continue\n",
    "    lines = open(os.path.join(t_d,ins_file),'r').readlines()\n",
    "    df = pst.drop_observations(os.path.join(t_d,ins_file),pst_path=\".\")\n",
    "    if ins_file == \"sfr.csv.ins\":\n",
    "        sdf = df\n",
    "    with open(os.path.join(t_d,ins_file),'w') as f:\n",
    "        for line in lines[:3]:\n",
    "            f.write(line.replace(\"_totim:3652.5\",\"\").replace(\"_time:3652.5\",\"\"))\n",
    "    pst.add_observations(os.path.join(t_d,ins_file),pst_path=\".\")\n",
    "assert sdf is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.loc[:,\"k\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[1]))\n",
    "hdf.loc[:,\"i\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[2]))\n",
    "hdf.loc[:,\"j\"] = hdf.usecol.apply(lambda x: int(x.split(\"-\")[3]))\n",
    "hdf.loc[:,\"time\"] = hdf.time.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d91d695e32284e5f4db43d0a55a7ffe722d99eb6050b5b06eff0d966e4449445"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
